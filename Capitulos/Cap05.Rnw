\chapter{Aplicaciones Multilineales}


\section{Aplicaciones Multilineales}

Sea $\mathbb{K}$ un cuerpo y sean $E_1, E_2,\ldots, E_p, F$ espacios vectoriales sobre $\mathbb{K}$.
\begin{definition}
Diremos que la aplicación $\varphi$ de $E=E_1\times E_2\times \ldots \times E_n$ en $F$ 
\begin{center}
\begin{tabular}{rcl}
$\varphi$: $E_1\times E_2\times \ldots \times E_n$ & $\to$ & F\\
$x=(x_1,x_2,\ldots, x_p)$ & $\to$ & $\varphi(x)$\\
\end{tabular}
\end{center}
es multilineal si $\varphi$ es lineal respecto a cada variable, es decir, si cualesquiera que sean $\alpha \in \mathbb{K}$, y $x_i \in E_i$ con $1\leq i\leq n$ se satisface
\begin{align*}
\varphi(x_1, \ldots, x_{i-1}, (\alpha x_i+y_i), x_{i+1},\ldots, x_p) =& \alpha \varphi(x_1,\ldots, x_{i-1}, x_i, x_{i+1},\ldots, x_p) +\\
& \varphi(x_1,\ldots,x_{i-1}, y_i, x_{i+1},\ldots, x_p)
\end{align*}
\end{definition}


\begin{example}[Determinante de una matriz]
\begin{center}
\begin{tabular}{rcl}
det: $\mathbb{R}^n\times\mathbb{R}^n\times \ldots \times \mathbb{R}^n$ & $\to$ & $\mathbb{R}$\\
$(x_1,x_2,\ldots, x_n)$ & $\to$ & det $\left([x_1] \ [x_2]\ \ldots \ [x_n]\right)$
\end{tabular}
\end{center}
{\small
\begin{align*}
\text{det} \left([x_1] \ldots [\alpha x_i + y_i] \ldots [x_n]\right) & = 
\text{det} \left([x_1] \ldots [\alpha x_i] \ldots [x_n]\right) + \text{det} \left([x_1] \ldots [y_i] \ldots [x_n]\right)\\
&= \alpha \ \text{det} \left([x_1] \ldots [x_i] \ldots [x_n]\right) + \text{det} \left([x_1] \ldots [y_i] \ldots [x_n]\right)
\end{align*}
}
\end{example}

Si $F=\mathbb{K}$ entonces la aplicación es una forma multilineal

\section{Formas Multilineales}

\begin{definition}
Llamaremos forma multilineal a la aplicación $\phi$ de $E_1\times E_2\times \ldots \times E_n$ en $\mathbb{K}$ que es lineal respecto a cada una de sus variables. Es decir, para cualesquiera $\alpha \in \mathbb{K}$ y $x_i\in E_i$ con $1\leq i \leq n$ se verifica que
\begin{align*}
\phi(x_1, \ldots, x_{i-1}, (\alpha x_i+y_i), x_{i+1},\ldots, x_p) =& \alpha \phi(x_1,\ldots, x_{i-1}, x_i, x_{i+1},\ldots, x_p) +\\
& \phi(x_1,\ldots,x_{i-1}, y_i, x_{i+1},\ldots, x_p)
\end{align*}
\end{definition}

\begin{definition}
Una forma multilineal $\phi$ es alternada, si para cualesquiera $i,j$ se tiene
\[\phi(x_1,\ldots, x_i, \ldots x_j,\ldots, x_n)=-\phi(x_1,\ldots, x_j, \ldots x_i,\ldots, x_n)\]
\end{definition}

\begin{teorema}
Dada una base ordenada $\{e_1, e_2, \ldots, e_n\}$ de un espacio vectorial $V$, existe una única forma multilineal alternada $D$ de orden $n$ que verifica
\[D(e_1, e_2, \ldots, e_n)=1\]
A dicha n-forma se le llama determinante.
\end{teorema}

Así, si $x_1, x_2,\ldots x_n$ son vectores de $V$, expresadas sus coordenadas respecto a la base $B$ del teorema anterior en la siguiente matriz cuadrada $M=(x_1\quad x_2\quad \ldots\quad x_n)$ formada por las coordenadas de los vectores puestos en columna, se tiene
\[D(x_1, x_2, \ldots, x_n)=\text{det} [x_1\quad x_2\quad \ldots \quad x_n]\]

De la definición y del teorema anterior se derivan todas las propiedades que conocemos sobre los determinantes.\newline

Nos interesaremos en las aplicaciones de $E_1\times E_2$ en $F$ también conocidas como aplicaciones bilineales de $E_1\times E_2$ en $F$.

\section{Aplicaciones Bilineales}

\begin{definition}
Dados tres espacios vectoriales $U,V,W$ sobre el cuerpo $\mathbb{K}$, una aplicación $f:U\times V\to W$ se dice que es bilineal si es lineal en cada una de sus variables, es decir:
\[f(\alpha u_1 + u_2, v1)= \alpha f(u_1, v_1) + f(u_2, v_1)\]
\[f(u_1, \alpha v1+v_2)= \alpha f(u_1, v_1) + f(u_1, v_2)\]
para cualesquiera $\alpha\in \mathbb{K}$, $u_1,u_2\in U$ y $v_1,v_2\in V$.
\end{definition}




%\chapter{Formas bilineales y formas cuadráticas}

% \begin{center}
% \shadowbox{
% \begin{minipage}{5in}
% {% \fontfamily{calligra}\fontsize{12}{4}\selectfont{
%  En este capítulo se efectúa un estudio sistemático de las formas bilineales simétricas y de las formas cuadráticas sobre un espacio vectorial que han sido utilizadas en capítulos anteriores, y en particular, los problemas de diagonalización y de clasificación de formas cuadráticas.}
%  \end{minipage}}
%  \end{center}
 
 %************************************************APLICACIONES MULTILINEALES******************************************
 
% \section{Aplicaciones Multilineales}
%\subsection{Definición}
 
%  \defi {Sean $E_1,E_2,E_3,\ldots,E_p,F,\mathbb{K}-e.v(espacios vectoriales)\\
%  $ E=E_1\times E_2 \times \ldots \times E_p $ en $F$ y $x=(x_1,x_2,\ldots ,x_p)
%  una aplicación de \\
%  $ \phi \colon E \longrightarrow F \\
%  x \mapsto \phi(x)$\\
%  $ \phi $ se dice multilineal si es lineal respecto a cada variable, es decir\\
%  $ \phi (x_1,x_2,x_3,\ldots ,x_{i-1},[\alpha x_i+y_i],x_{i+1},\ldots ,x_p) = \alpha \phi (x_1,x_2,x_3,\ldots ,x_{i-1},x_i,x_{i+1},\ldots ,x_p)+ \phi (x_1,x_2,x_3,\ldots ,x_{i-1},y_i,x_{i+1},\ldots ,x_p)$ }
%  
 

 %***********************************formas bilineales**********************************************
%  
\section{Formas bilineales}

\begin{definition}
Una forma bilineal es una aplicación bilineal en la que el espacio vectorial final es el cuerpo $\mathbb{K}$:
\[f:U\times V \to \mathbb{K}\]
\end{definition}

\subsection{Expresión matricial de una forma bilineal}



% \subsection*{Definición y propiedades}
% 
% \defi {\em Una forma bilineal de $E$ es una aplicación 
% \begin{center}
% $\begin{array}{rcl}
% f:E\times E&\to &\m{K}\\
% (u,v)&\mapsto &f(u,v)\\
% \end{array}$
% \end{center}
% tal que 
% \begin{enumerate}
% \item $f(u+v,w)=f(u,w)+f(v,w)$,\qquad $\forall~u,v,w\in E$
% \item $f(\alpha u,v)=\alpha f(u,v)$,\qquad $\forall~u,v\in E$ y $\forall~\alpha \in \m{K}$
% \item $f(u,v+w)=f(u,v)+f(u,w)$,\qquad $\forall~u,v,w\in E$
% \item $f(u,\beta v)=\beta f(u,v)$,\qquad $\forall~u,v\in E$ y $\forall~\beta \in \m{K}$
% \end{enumerate} 
% Observe que lo anterior es equivalente a verificar que 
% \begin{itemize}
% 	\item $\forall~\alpha,\beta\in \m{K}$ y $\forall~u,v,w\in E$ 
% 	\[f(\alpha u+\beta v,w)=\alpha f(u,w)+\beta f(v,w)\]
% 	\item $\forall~\alpha,\beta\in \m{K}$ y $\forall~u,v,w\in E$
% 	\[f(u,\alpha v+\beta w)=\alpha f(u,v)+\beta f(u,w)\]
% \end{itemize}
% es decir, una aplicación $f:E\times E\to \m{K}$ es una forma bilineal si es lineal en cada una de sus componentes.\\[3mm]
% 
% {\bf Ejemplos:}
% \begin{enumerate}
% 	\item La aplicación trivial $0:E\times E\to \m{K}$ es bilineal.
% 	\item La aplicación $f:\m{R}^n\times \m{R}^n\to \m{R}$, tal que $\displaystyle f(u,v)=\sum_{i=1}^n u_i v_i$ es bilineal y se llama producto euclídeo de $\m{R}^n$.
% 	\item La aplicación $f((x_1,x_2),(y_1,y_2))=x_1y_2-x_2y_1$ es una forma bilineal en $\m{R}^2$, que es justamente el determinante de la matriz 
% 	\[\left(\begin{array}{cc} x_1&x_2\\ y_1&y_2 \end{array}\right)\]
% 	\item La aplicación $f:\mathcal{M}(\m{R})_{m\times n}\times \mathcal{M}(\m{R})_{m\times n}\to \m{R}$, tal que $f(A,B)=tr(AB^T)$ es bilineal.
% 	
% 	\item Si $f$ y $g$ son formas bilineales sobre dos espacios vectoriales $E$ y $F$, entonces $f\times g$ es bilineal en $E\times F$.
% 	
% 	\item Dado $\m{R}^2$, la aplicación $f$ definida por: 
% 	\begin{center}
% 	$\begin{array}{rccl}
% 	f:&\m{R}^2\times \m{R}^2&\to &\m{R}\\
% 	&((x_1,x_2),(y_1,y_2))&\mapsto&x_1y_2\\
% 	\end{array}$
% 	\end{center}
% 	es una forma bilineal, ya que para todo $(x_1,x_2),~(y_1,y_2),~(z_1,z_2)\in \m{R}^2$ y $\alpha,\beta\in \m{K}$ se tiene que
% 	\[f(\alpha(x_1,x_2)+\beta(y_1,y_2), (z_1,z_2) )=f((\alpha x_1+\beta_1y_1, \alpha x_2+\beta y_2),(z_1,z_2))=(\alpha x_1+\beta y_1)z_2\]
% 	\[\alpha f((x_1,x_2),(z_1,z_2))+\beta f((y_1,y_2),(z_1,z_2))=\alpha (x_1,z_2)+\beta (y_1,z_2)\]  
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% 
% \pro {\em En un espacio vectorial, la única aplicación que es lineal y bilineal a la vez es la aplicación trivial.}\\
% \pro {\em Sea $f$ una forma bilineal en un espacio vectorial. Entonces se tiene 
% 
% \begin{enumerate}
% 	\item $f(0,u)=f(v,0)=0$, \qquad $\forall~u,v\in E$.
% 	\item $f(-u,v)=f(u,-v)=-f(u,v)$, \qquad $\forall~u,v\in E$.
% 	\item Si $u_1,u_2,\ldots,u_n,v_1,v_2,\ldots,v_n\in E$ y $\alpha_1,\alpha_2,\ldots,\alpha_n,\beta_1,\beta_2,\ldots,\beta_n\in \m{R}$, entonces 
% 	\[f\left(\sum_{i=1}^n \alpha_i u_i~,~\sum_{j=1}^n \beta_j v_j\right)=\sum_{i=1}^n \sum_{j=1}^n \alpha_i \beta_i f(u_i,v_j)\]
% \end{enumerate}}
% 
% \defi {\em Una forma bilineal $f:E\times E\to \m{K}$ es {\bf simétrica} si} \[f(u,v)=f(v,u)\qquad \forall~v,u\in E.\]
% \defi {\em Una forma bilineal $f:E\times E\to \m{K}$ es {\bf antisimétrica} si} \[f(v,u)=-f(u,v)\qquad \forall~v,u\in E.\]
% \lem {\em Sea $E$ un espacio vectorial sobre $\m{K}$ y $f:E\times E\to \m{K}$ una forma bilineal. Si $\m{K}=\m{R}$ o $\m{K}=\m{C}$ se verifica que $f$ es antisimétrica sí y solo si $f(v,v)=0$, para cada $v\in E$.\\
% 
% {\bf Ejemplos:}
% \begin{enumerate}
% 	\item La aplicación $T$ definida como: \[\begin{array}{rccl} T:&\m{R}^2\times \m{R}^2&\to& \m{R}\\ &(x,y)&\mapsto&T(x,y)=\det [x:y] \end{array}\] 
% 	es una forma bilineal antisimétrica.\\[2mm]
% 	
% 	\item La aplicación $f$ definida por: \[\begin{array}{rccl} f:&\m{R}^3\times \m{R}^3&\to &\m{R}\\ &(x,y)&\mapsto& f(x,y)=2x_1y_1+3x_2y_3-x_3y_3 \end{array}\]
% 	es una forma bilineal, pero no es simétrica, ni antisimétrica.\\[2mm]
% 	
% 	\item La aplicación $f$ definida como: \[\begin{array}{rccl} f:&\m{R}^2\times \m{R}^2 &\to &\m{R}\\ &(x,y)&\mapsto& f(x,y)=3x_1y_1-x_2y_1- x_1y_2-x_2y_2 \end{array}\] 
% 	es un forma bilineal simétrica.\\[2mm]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% %************************************************Representación Matricial******************************************
% 
% \section{Representación matricial de formas bilineales}
% {\em Sea $E$ un espacio vectorial de dimensión $n$.\\ Si $B=\{e_1,e_2,\ldots,e_n\}$ es una base ordenada de $E$ y $f$ una forma bilineal en $E$, además $x,y\in E$, entonces llamaremos matriz de $f$ respecto a dicha base a: \[A=(a_{ij})_{m\times n}\qquad\mbox{tal que } a_{ij}=f(e_i,e_j)\] es decir} \[A=\left(\begin{array}{cccc} f(e_1,e_1)& f(e_1,e_2)&\ldots &f(e_1,e_n)\\ f(e_2,e_1)&f(e_2,e_2)&\ldots&f(e_2,e_n)\\ \vdots&\vdots &\ddots &\vdots\\ f(e_n,e_1)& f(e_n,e_2)&\ldots&f(e_n,e_n)\end{array}\right)\]
% 
% \teo {\em Sea $f:E\times E\to \m{R}$ una forma bilineal. Sea $B=\{e_1,e_2,\ldots,e_n\}$ una base ordenada de $E$. Entonces $A$ es la única matriz, tal que para todo $x,y\in E$ se cumple \[f(x,y)=[x]_{B}^t A [y]_{B}\]
% {\bf Demostración:}\\[2mm]
% Sea \[x=\sum_{i=1}^n x_ie_i\qquad \Rightarrow\qquad [x]_B=\left[\begin{array}{c}x_1\\ x_2\\ \vdots\\ x_n \end{array}\right]\] 
% \[y=\sum_{j=1}^n y_je_j\qquad \Rightarrow\qquad [y]_B=\left[\begin{array}{c}y_1\\ y_2\\ \vdots\\ y_n \end{array}\right]\]
% Entonces \begin{eqnarray*} f(x,y)&=&f\left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j\right)\\ &=&\sum_{i=1}^n x_i f\left(e_i, \sum_{j=1}^n y_je_j\right)\\ &=&\sum_{i=1}^n x_i \sum_{j=1}^n y_j f(e_i,e_j)\\ &=&\sum_{i=1}^n \sum_{j=1}^n x_i f(e_i,e_j) y_j\\ &=&[x]_{B}^t A [y]_{B} \end{eqnarray*}
% \begin{flushright}
% $\blacksquare$
% \end{flushright}
% 
% Esta expresión recibe el nombre de ecuación matricial de la forma bilineal $f$, y la matriz $A$ el de matriz asociada a $f$ respecto de la base $B$.\\[2mm]
% Esta representación matricial depende de la base $B$.\\
%  Si una matriz tiene esta propiedad, aplicándola a los vectores $e_i$ y $e_j$ obtenemos que su componente $(i,j)$ ha de ser precisamente $f(e_i,e_j)$.\\[2mm]
% 
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item Calcular las  matrices asociadas a la forma bilineal $f:\m{R}^2 \times \m{R}^2\to \m{R}$ definida por \[f((x_1,x_2),(y_1,y_2))=x_1y_2+x_2y_1\] en la base canónica y en la base $B=\{(1,-1),(-1,0)\}$.\\[2mm]
% 	Primero calculemos la matriz $A$ asociada a $f$ en la base canónica:
% 	\[A=\left(\begin{array}{cc} f((1,0),(1,0))&f((1,0),(0,1))\\ f((0,1),(1,0))& f((0,1),(0,1))\end{array}\right)=\left(\begin{array}{cc} 0&1\\ 1&0\end{array}\right)\]
% 	
% 	ahora calculemos la matriz $A'$ asociada a $f$ en la base $B$:
% 	\[A'=\left(\begin{array}{cc} f((1,-1),(1,-1))&f((1,-1),(-1,0))\\ f((-1,0),(1,-1))& f((-1,0),(-1,0))\end{array}\right)=\left(\begin{array}{cc} -2&1\\ 1&0\end{array}\right)\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% A partir de la matriz asociada a una forma bilineal podremos decir si esta es simétrica o antisimétrica.}\\[2mm]
% \pro {\em Sea $E$ un espacio vectorial de dimensión finita, $f$ una forma bilineal en $E$ y sea $A$ la matriz asociada a $f$ respecto de alguna base de $E$. Entonces 
% \begin{enumerate}
% 	\item $f$ es simétrica\qquad $\Leftrightarrow$\qquad $A$ es una matriz simétrica.
% 	\item $f$ es antisimétrica \qquad $\Leftrightarrow$\qquad $A$ es una matriz antisimétrica.
% \end{enumerate}
% {\bf Demostración:}\\[2mm]
% 
% Si $f$ es simétrica
% \begin{eqnarray*}
% a_{ij}&=&f(e_i,e_j)\\
% &=&f(e_j,e_i)\\
% &=&a_{ji}
% \end{eqnarray*}
% Recíprocamente, si $A$ es simétrica
% \begin{eqnarray*}
% f(x,y)&=&\sum_{i,j=1}^n x_i a_{ij} y_j\\
% &=&\sum_{i,j=1}^n y_j a_{ji} x_i\\
% &=&f(y,x)
% \end{eqnarray*}}
% \begin{flushright}
% $\blacksquare$
% \end{flushright}
% 
% 
% 
% \pro {\em Toda forma bilineal puede descomponerse como la suma de una forma bilineal simétrica y una antisimétrica.\\[2mm]
% {\bf Demostración: }\\[2mm]
% Basta ver que si $f$ es bilineal se puede escribir como \[f=\frac{1}{2}(f +f^t)+\frac{1}{2}(f -f^t)\] donde \[\psi=\frac{1}{2}(f +f^t) \qquad \mbox{ es simétrica, y}\] \[\varphi=\frac{1}{2}(f -f^t)\qquad \mbox{ es antisimétrica.}\] 
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% 
% %***************************************RELACIÓN DE CONGRUENCIA**************************************
% 
% \section{Relación de congruencia}
% \pro[\bf Cambio de base] {\em Sea $f:E\times E\to \m{K}$ una forma bilineal, $\dim V=n$, además $B,B'$ bases de $E$ y $C_{B'\to B}$ la matriz cambio de base $B'$ a la base $B$. Sean $x,y\in E$ con: \[x_B=(x_1,x_2,\ldots,x_n)\qquad x_{B'}=(x'_1,x'_2,\ldots,x'_n)\] \[y_B=(y_1,y_2,\ldots,y_n)\qquad y_{B'}=(y'_1,y'_2,\ldots,y'_n)\] \[\fbox{$M_{B'}f=C^t_{B'\to B}~M_B f~C_{B'\to B}$}\footnote{$M_B f$ representa la matriz asociada a la forma bilineal $f$ respecto a la base $B$.}\]
% {\bf Demostración:}\\[2mm] 
% Así pues, se tiene \[\left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n\end{array}\right)=C_{B'\to B} \left(\begin{array}{c} x'_1\\ x'_2\\ \vdots\\ x'_n\end{array}\right)\qquad y \qquad \left(\begin{array}{c} y_1\\ y_2\\ \vdots\\ y_n\end{array}\right)=C_{B'\to B}\left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right)\]
% entonces 
% \begin{eqnarray*}
% f(x,y)&=&(x_1,x_2,\ldots,x_n)~M_Bf~\left(\begin{array}{c} y_1\\ y_2\\ \vdots\\ y_n\end{array}\right)\\
% &=&\left(C_{B'\to B}\left(\begin{array}{c} x'_1\\ x'_2\\ \vdots\\ x'_n\end{array}\right)\right)^t~M_Bf~C_{B'\to B} \left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right)\\
% &=&(x'_1, x'_2, \ldots, x'_n) \underbrace{C^t_{B'\to B}~M_B f~C_{B'\to B}}_{M_{B'}f}\left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right)\\ &=&(x'_1,x'_2,\ldots,x'_n)~M_{B'}f~\left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right) 
% \end{eqnarray*}
% \begin{flushright}
% $\blacksquare$
% \end{flushright}
% 
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item Sea $f:\m{R}^2\times \m{R}^2\to \m{R}$ definida por \[f((x_1,x_2),(y_1,y_2))=x_1y_2+x_2y_1\] donde $B$ es la base canónica y $B'=\{(1,-1),(-1,0)\}$. Entonces
% 	\[\underbrace{\left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right)}_{M_Bf}=\underbrace{\left(\begin{array}{rr} 0&-1\\ -1&-1\end{array}\right)}_{C^T_{B'\to B}} \underbrace{\left(\begin{array}{rr} -2&1\\ 1&0\end{array}\right)}_{M_{B'}f}\underbrace{\left(\begin{array}{rr} 0&-1\\ -1&-1\end{array}\right)}_{C_{B\to B'}}\]
% 	
% 	\[\underbrace{\left(\begin{array}{rr} -2&1\\ 1&0\end{array}\right)}_{M_{B'}f}=\underbrace{\left(\begin{array}{rr} 1&-1\\ -1&0\end{array}\right)}_{C^T_{B\to B'}} \underbrace{\left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right)}_{M_Bf}\underbrace{\left(\begin{array}{rr} 1&-1\\ -1&0\end{array}\right)}_{C_{B'\to B}}\]
% \end{enumerate}}
% 
% 
% %******************************************RANGO DE UNA FORMA BILINEAL************************************************
% 
% \section{Rango de una forma bilineal}
% \defi {\em Sea $f:E\times E\to \m{K}$ una forma bilineal, $\dim E=n$, se define el \emph{\bf rango} de una forma bilineal como el rango de la matriz $A$, asociada a la forma bilineal $f$ respecto a una base $B$ cualquiera de $E$.
% 
% {\bf Ejemplos:}
% \begin{enumerate}
% 	\item Sea $f:\m{R}^2\times \m{R}^2\to \m{R}$ una forma bilineal definida por \[f(x,y)=3x_1y_1+x_2y_1+x_1y_2+2x_2y_2\] ¿Cuál es el rango de $f$ ?.\\
% 	La matriz de $f$ asociada a la base canónica es: 
% 	\[A=\left(\begin{array}{cc} f(e_1,e_1)&f(e_1,e_2)\\ f(e_2,e_1)&f(e_2,e_2)\end{array}\right)=\left(\begin{array}{cc} 3&1\\ 1&2\end{array}\right)\] 
% 	y por tanto el $rg(f)=2$.
% 	
% 	\item Sea $f:\m{R}^3\times \m{R}^3\to \m{R}$ definida por \[f((x_1,x_2,x_3),(y_1,y_2,y_3))=x_1y_1-x_3y_3+x_1y_2\] ¿Encuentre el rango de $f$ ?.\\
% 	\[A'=\left(\begin{array}{rrr} f(e_1,e_1)&f(e_1,e_2)&f(e_1,e_3)\\ f(e_2,e_1)&f(e_2,e_2)&f(e_2,e_3)\\ f(e_3,e_1)&f(e_3,e_2)&f(e_3,e_3)\end{array} \right)=\left(\begin{array}{rrr} 1&1&0\\ 0&0&0\\ 0&0&-1\end{array}\right)\]
% 	y por tanto el $rg(f)=2$.
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% \defi {\em Una forma bilineal $f:E\times E\to \m{K}$, $\dim E=n$, se dice que es degenerada si su rango es menor que $n$. Mientras que si su rango es $n$, entonces es no degenerada.\\[2mm]
%  Es decir, una forma bilineal $f:E\times E\to \m{K}$, $\dim E=n$, es degenerada si y sólo si $\det(M_B f)=0$ y es no degerada si y sólo si $\det (M_B f)\neq 0$.} 
%  
%  
%  %********************************************FORMAS CUADRÁTICAS*********************************************************
%  
% \section{Formas cuadráticas} 
% \subsection*{Definición y propiedades}
% \defi {\em Sea $f:E\times E\to \m{K}$ una forma bilineal simétrica. Se llama forma \emph{cuadrática} asociada a $f$ a la aplicación  
% \begin{center}
% $\begin{array}{rcl}
% Q_f:E&\to &\m{K}\\
% x&\mapsto &Q_f(x)=f(x,x)\\
% \end{array}$
% \end{center}
% tal que 
% \begin{enumerate}
% 	\item $Q(0)=0$.
% 	\item $Q(\lambda x)=\lambda^2 Q(x)$.
% 	\item $Q(x+y)=Q(x)+Q(y)+2f(x,y)$.
% \end{enumerate}
% Distintas formas bilineales pueden dar lugar a la misma forma cuadrática. De hecho, si $f$ es una forma bilineal simétrica y $Q$ es la forma cuadrática asociada a $f$, entonces para cada forma bilineal antisimétrica $g$ se tiene 
% \[Q(x)=f(x,x)=f(x,x)+g(x,x)\] 
% pues $g(x,x)=0$ al ser antisimétrica, así $Q$ también es la forma cuadrática de $f+g$.\\[2mm]
% Esto es, la forma cuadrática asociada a una forma bilineal sólo depende de la parte simétrica de esta.\\[2mm]
% 
% {\bf Ejemplos:}\\[2mm]
% Calcule la forma cuadrática asociada a las siguientes formas bilineales 
% \begin{enumerate}
% 	\item Sea $f:\m{R}^2\times \m{R}^2\to \m{R}$ definida por \[f(x,y)=f((x_1,x_2),(y_1,y_2))=x_1y_2+x_2y_1\] 
% 	entonces \[Q_f(x)=f((x_1,x_2),(x_1,x_2))=2x_1x_2\]
% 	\item Sea $f:\m{R}^2\times \m{R}^2\to \m{R}$ definida por \[f(x,y)=f((x_1,x_2),(y_1,y_2))=3x_1y_1+x_2y_1+x_1y_2+2x_2y_2\]
% 	entonces \[Q_f(x)=f((x_1,x_2),(x_1,x_2))=3x_1^2+2x_1x_2+2x_2^2\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% Se pueden definir formas cuadráticas asociadas a formas bilineales no simétricas aunque nosotros sólo estudiaremos el caso de las formas cuadráticas asociadas a formas bilineales simétricas.}\\[2mm]
% 
% \pro {\em Sea $f$ una forma bilineal simétrica y $Q:E\to \m{K}$ su forma cuadrática asociada. Entonces
% \[f(x,y)=\frac{1}{2}[Q(x+y)-Q(x)-Q(y)]\]
% {\bf Demostración:}\\[2mm]
% \indent Se obtiene directamente despejando  el tercer apartado de las propiedades de las formas cuadráticas.
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
%    
% \pro {\em Dada una forma cuadrática $Q$ en $E$, entonces existe una única forma bilineal simétrica $f_p$ cuya forma cuadrática asociada es $Q$.\\[2mm]
% Tal forma bilineal simétrica recibe el nombre de forma \emph{polar} de la forma cuadrática $Q$.}\\[2mm]
% 
% \cor {\em Sea $Q$ una forma cuadrática en $E$ asociada a la forma bilineal $g$. La forma polar $f_p$ de $Q$ se puede obtener como:
% \begin{enumerate}
% 	\item $f_p(x,y)=\frac{1}{2}\left[Q(x+y)-Q(x)-Q(y)\right]$.
% 	\item $f_p(x,y)=\frac{1}{4}\left[Q(x+y)-Q(x-y)\right]$.
% 	\item $f_p(x,y)=\frac{1}{2}\left[g(x,y)+g(y,x)\right]$.
% \end{enumerate}}
% 
% 
% %******************************************ESPRESIÓN MATRICIAL DE UNA FORMA CUADRÁICA****************************************
% 
% \section{Expresión matricial de una forma cuadrática}
% \subsection*{Cambios de base}
% 
% {\em Consideremos una forma cuadrática $Q:E\to \m{K}$ asociada a la forma bilineal simétrica \[f:E\times E\to \m{K}\]
% Sea $B=\{x_1,x_2,\ldots,x_n\}$ una base de $E$, como $f$ es simétrica tenemos que \[f(x_i,x_j)=f(x_j,x_i)\qquad \forall~i,j=1,2,\ldots,n\]
% Por tanto 
% \begin{eqnarray*}
% Q(x)=f(x,x)&=&{(x_1,x_2,\ldots,x_n)\left(\begin{array}{cccc} f(x_1,x_1)&f(x_1,x_2)&\ldots&f(x_1,x_n)\\ f(x_2,x_1)&f(x_2,x_2)&\ldots&f(x_2,x_n)\\ \vdots&\vdots&\ddots&\vdots\\ f(x_n,x_1)&f(x_n,x_2)&\ldots&f(x_n,x_n)\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right)}\\
% &=&{(x_1,x_2,\ldots,x_n)\left(\begin{array}{cccc} f(x_1,x_1)&f(x_1,x_2)&\ldots&f(x_1,x_n)\\ f(x_2,x_1)&f(x_2,x_2)&\ldots&f(x_2,x_n)\\ \vdots&\vdots&\ddots&\vdots\\ f(x_1,x_n)&f(x_2,x_n)&\ldots&f(x_n,x_n)\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n \end{array} \right)}
% \end{eqnarray*}}
% 
% \defi {\em La matriz \[A=\left(\begin{array}{cccc} f(x_1,x_1)&f(x_1,x_2)&\ldots&f(x_1,x_n)\\ f(x_2,x_1)&f(x_2,x_2)&\ldots&f(x_2,x_n)\\ \vdots&\vdots&\ddots&\vdots\\ f(x_n,x_1)&f(x_n,x_2)&\ldots&f(x_n,x_n)\end{array}\right)\]
% se dice que es la matriz de la forma cuadrática $Q$ asociada a la base $B$ de $E$, es decir $A=M_BQ$.
% 
% Observe que $M_BQ$ es siempre una matriz simétrica. Por tanto, si denotamos por \[f(x_i,x_j)=f(x_j,x_i)=b_{ij}\qquad \forall~i,j=1,2,\ldots,n\]
% obtenemos 
% \begin{eqnarray*}
% Q(x)=f(x,x)&=&\sum_{i=1}^n b_{ij}x_i^2 +\sum_{1\leq i\leq j\leq n} 2b_{ij} x_ix_j\\
% &=&b_{11}x_1^2+b_{22}x_2^2+\ldots+b_{nn}x_n^2+2b_{12}x_1x_2+\ldots+2b_{1n}x_1x_n+2b_{23}x_2x_3+\ldots+\\
% && +2b_{2n}x_2x_n+2b_{34}x_3x_4+\ldots+2b_{3n}x_3x_n+\ldots+2b_{(n-1)n}x_{(n-1)}x_n
% \end{eqnarray*}
% 
% Para pasar de una expresión a otra hay que tener en cuenta que los elementos de la diagonal principal en la diagonal matricial resultan ser los coeficientes de los cuadrados en la expresión polinómica, y que los elementos restantes de la matriz resultan ser la mitad de los coeficientes de los términos no cuadráticos en la expresión polinómica.\\[2mm]
% 
% {\bf Ejemplos:}
% \begin{enumerate}
% 	\item Obtenga la expresión polinómica de la forma cuadrática, expresada matricialmente como:
% 	\[Q(x)=(x_1,x_2,x_3)\left(\begin{array}{ccc} 1&4&-1\\ 4&0&0\\ -1&0&2\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array}\right)\]
% 	Por tanto, la expresión polinómica es: 
% 	\[Q(x)=x_1^2+2x_3^2+8x_1x_2-2x_1x_3\]
% 	\item Obtenga la expresión matricial de la forma cuadrática, expresada polinómicamente como:
% 	\[Q(x)=x_2^2-5x_3^2-x_1x_2+4x_2x_3\]
% 	Por tanto, la expresión matricial es:
% 	\[Q(x)=(x_1,x_2,x_3)\left(\begin{array}{ccc} 0&-\frac{1}{2}&0\\ -\frac{1}{2}&1&2\\ 0&2&-5\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array}\right)\]
% 	\item Hallar la matriz asociada a $Q:\m{R}^4\to \m{R}$ con 
% 	\[Q(x_1,x_2,x_3,x_4)=x_1^2-2x_1x_2+2x_1x_3+2x_1x_4+x_2^2-2x_2x_3+2x_2x_4-x_3^2+2x_3x_4-x_4^2\] en la base canónica.
% 	\[M_BQ=\left(\begin{array}{rrrr} 1&-1&1&1\\ -1&1&-1&1\\ 1&-1&-1&1\\ 1&1&1&-1\end{array}\right)\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% \pro[\bf Cambios de base en formas cuadráticas] {\em Sea $Q:E\to \m{K}$ una forma cuadrática, $\dim E=n$, $B,B'$ bases de $E$ y $C_{B'\to B}$ la matriz del cambio de la base $B'$ a la base $B$. 
% \[\fbox{$M_{B'}Q=C^t_{B'\to B} M_{B}Q C_{B'\to B}$}\]
% {\bf Demostración:}\\[2mm]
% Sean $x,y\in E$ con: \[x_B=(x_1,x_2,\ldots,x_n)\qquad x_{B'}=(x'_1,x'_2,\ldots,x'_n)\]
% 
% Así pues, se tiene \[\left(\begin{array}{c} x_1\\ x_2\\ \vdots\\ x_n\end{array}\right)=C_{B'\to B} \left(\begin{array}{c} x'_1\\ x'_2\\ \vdots\\ x'_n\end{array}\right)\]
% entonces 
% \begin{eqnarray*}
% Q(x)&=&(x_1,x_2,\ldots,x_n)~M_BQ~\left(\begin{array}{c} y_1\\ y_2\\ \vdots\\ y_n\end{array}\right)\\
% &=&\left(C_{B'\to B}\left(\begin{array}{c} x'_1\\ x'_2\\ \vdots\\ x'_n\end{array}\right)\right)^t~M_BQ~C_{B'\to B} \left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right)\\
% &=&(x'_1, x'_2, \ldots, x'_n) \underbrace{C^t_{B'\to B}~M_B Q~C_{B'\to B}}_{M_{B'}Q}\left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right)\\ &=&(x'_1,x'_2,\ldots,x'_n)~M_{B'}Q~\left(\begin{array}{c} y'_1\\ y'_2\\ \vdots\\ y'_n\end{array}\right) 
% \end{eqnarray*}
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% 
% %************************************************ MATRICES CONGRUENTES*******************************************************
% 
% \section{Matrices congruentes} 
% 
% {\em A continuación estudiaremos cómo se relacionan las expresiones matriciales de las formas bilineales y cuadráticas en diferentes bases.\\[2mm]
% Sea $f(x)=x^t Ax$ una forma cuadrática de $E$, expresada en coordenadas respecto a una determinada base.\\[2mm]
% Si $P$ es una matriz invertible y hacemos el cambio lineal de coordenadas en $E$ \[Py=x\] tenemos que \[f(x)=(Py)^t A Py=y^t P^tAPy\] de donde se deduce que la matriz de $f$ respecto a la nueva base es} \[A'=P^tAP\]
% 
% \defi {\em Dos matrices $A$ y $A'$ reales y simétricas se dicen \emph{congruentes}, si existe una matriz $P$ invertible tal que \[A'=P^tAP\]
% Equivalentemente, dos matrices reales y simétricas son congruentes si representan la misma forma cuadrática respecto a diferentes bases de $E$.
% 
% Además las matrices congruentes entre sí tienen el mismo rango. Esto motiva la siguiente definición.}
% 
% \defi {\em Se define el rango de una forma cuadrática, como el rango de su matriz \emph{(simétrica)} respecto de cualquier base de $E$. }     
% 
% \obs {\em La simetría de la matriz es imprescindible en la definición anterior
% 
% Por ejemplo, la forma cuadrática de $\m{R}^2$ definida por \[f(x,y)=x^2+y^2+2xy\] puede escribirse como
% \[f(x,y)=\left(\begin{array}{cc} x&y \end{array}\right) \left(\begin{array}{cc} 1&1\\ 1&1\end{array}\right)\left(\begin{array}{cc} x\\ y\end{array}\right)=\left(\begin{array}{cc} x&y\end{array}\right)\left(\begin{array}{cc} 1&2\\ 0&1\end{array}\right)\left(\begin{array}{cc} x\\ y \end{array}\right)\]
% 
% siendo el rango de $f$ igual a $1$, que es el de la matriz simétrica. El rango $2$ de la segunda matriz no da información sobre la forma cuadrática, por no ser simétrica.
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% \pro {\em Sea $A,C\in \mathcal{M}(\m{K})$. Si $A$ es \emph{\bf congruente} con $C$ entonces se tiene que} \[rg(A)=rg(C).\]
% 
% 
% %******************************************DIAGONALIZACIÓN DE FORMAS CUADRÁTICAS***********************************************
% 
% \section{Diagonalización de formas cuadráticas}
% \defi {\em Sea $E$ un espacio vectorial, de dimensión $n$, y \[f:E\times E\to \m{K}\] una forma bilineal simétrica.\\[2mm]
% Decimos que $x,y\in E$ son conjugados respecto de $f$ si $f(x,y)=0$.}
% 
% \pro {\em Dado $x\in E$ el conjunto \[C_x=\{y\in E~/~f(x,y)=0\}\subset E\] es un subespacio vectorial de $E$.}
% 
% \pro {\em Si $f:E\times E\to \m{K}$ es una forma bilineal simétrica no idénticamente nula entonces existe $x\in E$ tal que \[f(x,x)\neq 0.\]
% {\bf Demostración:}\\[2mm]
% Puesto que \[f:E\times E \to \m{K}\] es una forma bilineal no idénticamente nula entonces existe $y,z\in E$ tal que \[f(y,z)\neq 0\] y como
% \[f(y+z,y+z)=f(y,y)+f(z,z)+2f(y,z)\] obtenemos que \[x=y+z,~x~\mbox{ó}~z.\]
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% \pro {\em Sea $x\in E$ con $f(x,x)\neq 0$ entonces \[E=C_x \oplus L\{x\}\]
% {\bf Demostración:}\\[2mm]
% Basta ver que:
% \begin{itemize}
% 	\item $C_x\cap L\{x\}=\{0\}$.
% 	\item Si $y\in E$ entonces se tiene \[y=\underbrace{\frac{f(y,x)}{f(x,x)}x}_{L\{x\}}+\underbrace{\left(y-\frac{f(y,x)}{f(x,x)}x\right)}_{C_x}\]
% \end{itemize}
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% \cor {\em Toda forma cuadrática o forma bilineal simétrica es diagonalizable. Por tanto, si $A\in \mathcal{M}(\m{R})$ es simétrica entonces $A$ es congruente con una matriz diagonalizable, es decir, existe una matriz invertible $P$ tal que} \[D=P^t A P\]
% 
% 
% %**********************************************MÉTODOS DE DIAGONALIZAR FORMAS CUADRÁTICAS************************************
% 
% \subsection{Métodos para diagonalizar formas cuadráticas}  
% 
% %*****************************************DIAGONALIZACIÓN POR CONGRUENCIA- SUMAS DE CUADRADOS*********************************
% 
% \subsubsection*{Diagonalización por congruencia. Sumas de cuadrados}
% \pro {\em Sea $E$ un espacio vectorial de dimensión $n$, además $f:E\times E\to \m{K}$ una forma bilineal simétrica y $Q:E\to \m{K}$ su forma cuadrática asociada.\\ Entonces existe una base $B=\{x_1,x_2,\ldots,x_n\}$ de $E$ tal que 
% \[M_BQ=\left(\begin{array}{cccc} a_{11}&0&\ldots&0\\ 0&a_{22}&\ldots&0\\ \vdots&\vdots&\ddots&\vdots\\ 0&0&\ldots&a_{nn}\end{array}\right)\]
% es decir, $f(x_i,x_j)=0$ para todo $i\neq j$ con $i,j\in \{1,2,\ldots,n\}$.\\
% Por tanto, la expresión en coordenadas de la forma cuadrática $Q$ respecto de la base $B$ es:
% \[Q(x)=a_{11}x_1^2+a_{22}x_2^2+\ldots\ldots+a_{nn}x_n^2\]
% 
% {\bf Demostración:}\\[2mm]
% Hacemos la demostración por inducción sobre la dimensión de $E$.\\
% Suponemos que $f$ es una forma bilineal simétrica no idénticamente nula, ya que en caso contrario siempre se verifica.\\
% 
% Es claro que si $\dim E=1$ ó $2$ se verifica. Supongamos que es cierto hasta $\dim E=n-1$.\\
% Sea $E$ un espacio vectorial con $\dim E=n$. Sea $y\in E$ con $f(y,y)\neq 0$ entonces \[E=C_y\oplus L\{y\}\]
% Como $\dim C_y=n-1$ por hipótesis de inducción tenemos que existe una base \[B_C=\{y_1,y_2,\ldots,y_{n-1}\}\] de $C_y$ tal que $f(y_i,y_j)=0$ para todo $i\neq j$ con $i,j\in \{1,2,\ldots,n-1\}$.\\ 
% Por tanto \[B=\{y_1,y_2,\ldots y_{n-1},x\}\] es la base que buscábamos.
% \begin{flushright}
% $\blacksquare$
% \end{flushright}
% 
% Llamaremos \emph{diagonalizar por congruencia} una matriz real y simétrica, a encontrar una matriz diagonal congruente con ella, así como la matriz de paso $P$ que relaciona ambas.\\[2mm]
%  
% Como veremos a continuación, el encontrar una matriz $P$ invertible que transforme mediante congruencia la matriz simétrica $A$ en una diagonal, es mucho más sencillo que la diagonalización ortogonal de $A$, pues la matriz $P$ no tiene por qué ser ortogonal.\\[2mm]
% 
% Se dice que una forma cuadrática está expresada como suma de cuadrados, cuando se tiene su expresión en coordenadas respecto a una determinada base.\\[2mm]
% 
% Reducir una forma cuadrática, mediante una cambio lineal de coordenadas, a una suma de cuadrados, es equivalente a diagonalizar por congruencia su matriz.}
% 
% 
% %**********************************************MEDIANTE OPERACIONES ELEMENTALES********************************************
% 
% \subsubsection*{Mediante operaciones elementales}
% {\em Dada una matriz real y simétrica $A$, si realizamos una operación elemental sobre sus filas y a continuación la misma operación sobre sus columnas, se conserva la simetría de la matriz.\\[2mm]
% 
% Ello equivale a la post y premultiplicación por una matriz elemental y su transpuesta: \[E_1^t A~ E_1\]
% Reiteramos este proceso hasta obtener una matriz diagonal \[E_k^t\ldots E_2^t E_1^t A~ E_1 E_2\ldots E_k=D\]
% es decir \[(E_1E_2\ldots E_k)^t A~ E_1E_2\ldots E_k=D\]
% Así pues, tomando \[P=E_1E_2\ldots E_k\]
% es decir, la matriz resultante de realizar sobre la identidad las mismas operaciones de columnas efectuadas sobre $A$, tenemos que \[P^t AP=D.\]
% 
% {\bf Ejemplos:}
% \begin{enumerate}
% 	\item Sea la forma cuadrática \[Q(x_1,x_2)=x_1x_2+x_1^2.\]
% 	La matriz asociada a la forma cuadrática en la base canónica de $\m{R}^2$ es:
% 	\[A=M_{B_C}Q=\left(\begin{array}{rr} 1&\frac{1}{2}\\ \frac{1}{2}&0\end{array}\right)\]
% 	Realizamos operaciones elementales en la matriz $A$ por filas: $F_2-\frac{1}{2}F_1$ y por columnas $C_2-\frac{1}{2}C_1$, es decir 
% 	\[\underbrace{\left(\begin{array}{rr} 1&0\\ -\frac{1}{2}&1\end{array}\right)}_{C^T_{B\to B_C}} \left(\begin{array}{rr} 1&\frac{1}{2}\\ \frac{1}{2}&0\end{array}\right)\underbrace{\left(\begin{array}{rr} 1&-\frac{1}{2}\\ 0&1\end{array}\right)}_{C_{B\to B_C}}=\underbrace{\left(\begin{array}{rr} 1&0\\ 0&-\frac{1}{4}\end{array}\right)}_{M_B Q}\] 
%  Obtenemos así que la matriz $M_B Q$ es la matriz de la forma cuadrática en la base \[B=\{(1,0),(-\frac{1}{2},1)\}\]
%  
%  \item Sea la forma cuadrática \[Q(x_1,x_2)=x_1x_2+x_2^2.\]
%  	La matriz asociada a la forma cuadrática en la base canónica de $\m{R}^2$ es:
% 	\[A=M_{B_C}Q=\left(\begin{array}{rr} 0&\frac{1}{2}\\ \frac{1}{2}&1\end{array}\right)\]
% 	Cambiamos las filas $F_1,F_2$ y las columnas $C_1,C_2$ de orden, es decir: 
% 	\[\left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right) \left(\begin{array}{rr} 0&\frac{1}{2}\\ \frac{1}{2}&1\end{array}\right) \left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right)=\left(\begin{array}{rr} 1&\frac{1}{2}\\ \frac{1}{2}&0\end{array}\right)\] 
% 	\[\left(\begin{array}{rr} 1&0\\ -\frac{1}{2}&1\end{array}\right) \left(\begin{array}{rr} 1&\frac{1}{2}\\ \frac{1}{2}&0\end{array}\right) \left(\begin{array}{rr} 1&-\frac{1}{2}\\ 0&1\end{array}\right)=\left(\begin{array}{rr} 1&0\\ 0&-\frac{1}{4}\end{array}\right)\]
% 	\[\underbrace{\left(\begin{array}{rr} 1&0\\ -\frac{1}{2}&1\end{array}\right) \left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right)}_{C^T_{B\to B_C}} \left(\begin{array}{rr} 0&\frac{1}{2}\\ \frac{1}{2}&1\end{array}\right) \underbrace{\left(\begin{array}{rr} 0&1\\ 1&0\end{array}\right) \left(\begin{array}{rr} 1&-\frac{1}{2}\\ 0&1\end{array}\right)}_{C_{B\to B_C}}=\underbrace{\left(\begin{array}{rr} 1&0\\ 0&-\frac{1}{4} \end{array}\right)}_{M_B Q}\]
%  Obtenemos así que la matriz $M_B Q$ es la matriz de la forma cuadrática en la base \[B=\{(0,1),(1,-\frac{1}{2})\}\]
%  
%  \item Sea la forma cuadrática \[Q(x_1,x_2,x_3)=x_1^2+2x_1x_2+3x_2^2+4x_1x_3+6x_2x_3+5x_3^2.\]
%  La matriz asociada a la forma cuadrática en la base canónica de $\m{R}^3$ es:
%  \[A=M_{B_C} Q=\left(\begin{array}{rrr} 1&1&2\\ 1&3&3\\ 2&3&5\end{array}\right)\]
%  Realizamos operaciones elementales en la matriz $A$,
%  \[\left(\begin{array}{rrr} 1&0&0\\ -1&1&0\\ -2&0&1\end{array}\right)\left(\begin{array}{rrr} 1&1&2\\ 1&3&3\\ 2&3&5\end{array}\right) \left(\begin{array}{rrr} 1&-1&-2\\ 0&1&0\\ 0&0&1\end{array}\right)=\left(\begin{array}{rrr} 1&0&0\\ 0&2&1\\ 0&1&1\end{array}\right)\]
%  	\[\left(\begin{array}{rrr} 1&0&0\\ 0&1&0\\ 0&-\frac{1}{2}&1\end{array}\right)\left(\begin{array}{rrr} 1&0&0\\ 0&2&1\\ 0&1&1\end{array}\right) \left(\begin{array}{rrr} 1&0&0\\ 0&1&-\frac{1}{2}\\ 0&0&1\end{array}\right)=\left(\begin{array}{rrr} 1&0&0\\ 0&2&0\\ 0&0&\frac{1}{2}\end{array}\right)\]
%  	\[\underbrace{\left(\begin{array}{rrr} 1&0&0\\ 0&1&0\\ 0&-\frac{1}{2}&1\end{array}\right)\left(\begin{array}{rrr} 1&0&0\\ -1&1&0\\ -2&0&1\end{array}\right)}_{C^T_{B\to B_C}} \left(\begin{array}{rrr} 1&1&2\\ 1&3&3\\ 2&3&5\end{array}\right) \underbrace{\left(\begin{array}{rrr} 1&-1&-2\\ 0&1&0\\ 0&0&1\end{array}\right) \left(\begin{array}{rrr} 1&0&0\\ 0&1&-\frac{1}{2}\\ 0&0&1\end{array}\right)}_{C_{B\to B_C}}=\underbrace{\left(\begin{array}{rrr} 1&0&0\\ 0&2&0\\ 0&0&\frac{1}{2}\end{array}\right)}_{M_B Q}\]
%  	\[\underbrace{\left(\begin{array}{rrr} 1&0&0\\ -1&1&0\\ -\frac{3}{2}&-\frac{1}{2}&1\end{array}\right)}_{C^T_{B\to B_C}} \left(\begin{array}{rrr} 1&1&2\\ 1&3&3\\ 2&3&5\end{array}\right) \underbrace{\left(\begin{array}{rrr} 1&-1&-\frac{3}{2}\\ 0&1&-\frac{1}{2}\\ 0&0&1\end{array}\right)}_{C_{B\to B_C}}=\underbrace{\left(\begin{array}{rrr} 1&0&0\\ 0&2&0\\ 0&0&\frac{1}{2}\end{array}\right)}_{M_B Q}\]
%  	Obtenemos así que la matriz $M_B Q$ es la matriz de la forma cuadrática en la base 
%  	\[B=\{(1,0,0), (-1,1,0), (-\frac{3}{2},-\frac{1}{2},1)\}\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}}
% 
% 
% %*************************************************COMPLETANDO CUADRADOS************************************************
% 
% \subsubsection*{Completando cuadrados}
% {\em Ahora vamos a ver que toda forma cuadrática no nula de $E$ puede reducirse a una suma de cuadrados de formas lineales, más una forma cuadrática \emph{residual} que depende de, a lo sumo, $n-1$ variables, sobre la cual se reiterará el procedimiento.\\[2mm]
% Así, en $n-1$ pasos como máximo, la forma cuadrática original quedará reducida a una suma de cuadrados.}
% 
% \begin{itemize}
% 	\item {\bf Primer Caso: } {\em Si tenemos que \[f(x)=\sum_{i=1}^n a_{ii}x_i^2 +2\sum_{i<j} a_{ij}x_ix_j\] con algún coeficiente diagonal no nulo, por ejemplo $a_{11}$, agrupamos los términos de la siguiente manera:}
% \end{itemize}
% 	\begin{eqnarray*}
% 	f(x)&=&a_{11}\left(x_1+\frac{a_{12}}{a_{11}}x_2+\ldots +\frac{a_{1n}}{a_{11}}x_n\right)^2-\sum_{j=2}^n \frac{a_{1j}^2}{a_{11}}x_j^2 -2\sum_{2<i<j} \frac{a_{1i}a_{1j}}{a_{11}}x_ix_j +\sum_{i=2}^n a_{ii}x_i^2 +\sum_{2<i<j} a_{ij}x_ix_j\\
% 	&=&a_{11}y_1^2 +\sum_{i=2}^n b_{ii}x_i^2 +\sum_{2\leq i<j} b_{ij}x_ix_j
% 	\end{eqnarray*}
%  {\em En donde hemos introducido la nueva variable \[y_1=x_1+\frac{a_{12}}{a_{11}}x_2+\ldots+\frac{a_{1n}}{a_{11}}x_n\] y los dos últimos sumandos constituyen una forma cuadrática de $E$ en las variables $x_2,x_3,\ldots,x_n$.}
%  
%  \begin{itemize}
%  \item {\bf Segundo Caso: } {\em Si son nulos todos los coeficientes diagonales $a_{ii}$, existirá algún $a_{ij}$ no nulo, con $i\neq j$; por ejemplo, $a_{12}\neq 0$. Entonces procedemos de la siguiente manera:}
%  \end{itemize}
%  \begin{eqnarray*}
%  f(x)&=&2\sum_{i\leq j} a_{ij}x_ix_j\\
%  &=&2a_{12}x_1x_2 +2x_1(a_{13}x_3+\ldots+a_{1n}x_n) +2x_2(a_{23}x_3+\ldots+a_{2n}x_n)+2\sum_{3\leq i<j} a_{ij}x_ix_j\\
%  &=& 2a_{12}\left(x_1+\frac{1}{2a_{12}}(a_{13}x_3+\ldots+a_{1n}x_n))\right)\left(x_2+\frac{1}{2a_{12}}(a_{23}x_3+\ldots+a_{2n}x_n)\right)+\\
%  & & +2\sum_{3<i<j}a_{ij}x_ix_j -\frac{1}{2a_{12}}(a_{13}x_3+\ldots+a_{1n}x_n)(a_{23}x_3+\ldots+a_{2n}x_n).
%  \end{eqnarray*} 	
%   {\em Hacemos ahora el cambio de variables definido por 
%  \[y_1+y_2=x_1+\frac{1}{2a_{12}}(a_{23}x_3+\ldots+a_{2n}x_n)\]
%  \[y_1-y_2=x_2+\frac{1}{2a_{12}}(a_{13}x_3+\ldots+a_{1n}x_n)\]
%  y la forma cuadrática puede escribirse de la forma:}
%  \begin{eqnarray*}
%  f(x)&=&2a_{12}(y_1+y_2)(y_1-y_2) -\frac{1}{2a_{12}}(a_{13}x_3+\ldots+a_{1n}x_n)(a_{23}x_3+\ldots+a_{2n}x_n)\\
%  &=&2a_{12}y_1^2-2a_{12}y_2^2+\sum_{i=3}^n b_{ii}x_i^2 +\sum_{3\leq i<j} b_{ij}x_ix_j  
%  \end{eqnarray*}
%  {\em de donde los dos últimos sumandos representan una forma cuadrática de $E$ en las variables $x_3,x_4,\ldots,x_n$.}\\[2mm]
%  
%  {\bf Ejemplos:}
% \begin{enumerate}
% 	\item {\em Sea la forma bilineal \[Q(x)=Q(x_1,x_2)=x_1^2+2x_1x_2+x_2^2\] como \[Q(x_1,x_2)=x_1^2+2x_1x_2+x_2^2=(x_1+x_2)^2\]
% 	si hacemos el cambio \[(x'_1, x'_2)=\left(\begin{array}{rr} 1&1\\ 0&1\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\end{array}\right)\]
% 	obtenemos que }
% 	\begin{eqnarray*}
% 	Q(x'_1,x'_2)&=&(x'_1)^2\\
% 	&=&(x'_1, x'_2)\left(\begin{array}{rr} 1&0\\ 0&0\end{array}\right)\left(\begin{array}{c} x'_1\\ x'_2\end{array}\right)\\
% 	&=&\left(\left(\begin{array}{rr} 1&1\\ 0&1\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\end{array}\right)\right)^T \left(\begin{array}{rr} 1&0\\ 0&0\end{array}\right) \left(\begin{array}{rr} 1&1\\ 0&1\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\end{array}\right)\\
% 	&=&(x_1,x_2)\left(\begin{array}{rr} 1&0\\ 1&1\end{array}\right) \left(\begin{array}{rr} 1&0\\ 0&0\end{array}\right) \left(\begin{array}{rr} 1&1\\ 0&1\end{array}\right) \left(\begin{array}{c} x_1\\ x_2\end{array}\right)\\
% 	&=&(x_1,x_2)\left(\begin{array}{rr} 1&1\\ 1&1\end{array}\right) \left(\begin{array}{c} x_1\\ x_2\end{array}\right)\\
% 	&=&x_1^2+x_2^2+2x_1x_2=Q(x_1,x_2)
% 	\end{eqnarray*}
% 	
% 	\item {\em Sea la forma bilineal \[Q(x)=Q(x_1,x_2,x_3)=x_1^2-4x_1x_2-2x_1x_3+4x_3^2\]
% 	Elegimos una variable y todos los factores que la contengan, por ejemplo $x_1$, y completamos un cuadrado}
% 	\begin{eqnarray*}
% 	Q(x_1,x_2,x_3)&=&x_1^2-4x_1x_2-2x_1x_3+4x_3^2\\
% 	&=&(x_1-2x_2-x_3)^2-x_3^2-4x_2^2-4x_2x_3+4x_3^2\\
% 	&=&(x_1-2x_2-x_3)^2-4(x_2+\frac{1}{2}x_3)^2+4x_3^2
% 	\end{eqnarray*}
% 	{\em hacemos el cambio} \[(x'_1,x'_2,x'_3)=\left(\begin{array}{rrr} 1&-2&-1\\ 0&1&\frac{1}{2}\\ 0&0&1\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array}\right)\]
% 	{\em obtenemos que }
% 	\begin{eqnarray*}
% 	Q(x'_1,x'_2,x'_3)&=&x_1^{'2}-4x_2^{'2}+4x_3^{'2}\\
% 	&=&(x'_1,x'_2,x'_3)\left(\begin{array}{rrr} 1&0&0\\ 0&-4&0\\ 0&0&4\end{array}\right)\left(\begin{array}{c} x'_1\\ x'_2\\ x'_3\end{array}\right)\\
% 	&=&\left( \left(\begin{array}{rrr} 1&-2&-1\\ 0&1&\frac{1}{2}\\ 0&0&1\end{array}\right)\left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array} \right) \right)^T \left(\begin{array}{rrr} 1&0&0\\ 0&-4&0\\ 0&0&4\end{array}\right) \left(\begin{array}{rrr} 1&-2&-1\\ 0&1&\frac{1}{2}\\ 0&0&1\end{array} \right) \left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array}\right)\\
% 	&=&(x_1,x_2,x_3) \left(\begin{array}{rrr} 1&0&0\\ -2&1&0\\ -1&-\frac{1}{2}&1\end{array}\right) \left(\begin{array}{rrr} 1&0&0\\ 0&-4&0\\ 0&0&4\end{array}\right) \left(\begin{array}{rrr} 1&-2&-1\\ 0&1&\frac{1}{2}\\ 0&0&1\end{array}\right) \left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array} \right)\\ 
% 	&=&(x_1,x_2,x_3) \left(\begin{array}{rrr} 1&-2&-1\\ -2&0&0\\ -1&0&4\end{array}\right) \left(\begin{array}{c} x_1\\ x_2\\ x_3\end{array} \right)\\
% 	&=&x_1^2-4x_1x_2-2x_1x_3+4x_3^2=Q(x_1,x_2,x_3)
% 	\end{eqnarray*}
% 	
% 	\item {\em Sea la forma bilineal \[Q(x)=Q(x,y,z,t)=xy+xz+yz+tz+xt\]
% 	elegimos un sumando: $xy$ y todos aquellos que tengan la variable $x$ o $y$, en nuestro caso \[xz+yz+xt\] entonces como 
% 	\[(x+z)(y+t+z)=xy+xt+xz+yz+zt+z^2\] tenemos que \[Q(x,y,z,t)=xy+xz+yz+tz=(x+z)(y+t+z)-z^2\] y haciendo el cambio de variable }
% 	\begin{eqnarray*}
% 	x+z&=&x'+y'\\
% 	y+t+z&=&x'-y'\\
% 	z&=&z'\\
% 	t&=&t'
% 	\end{eqnarray*} 
% 	{\em entonces} 
% 	\[\left(\begin{array}{c} x'\\ y'\\ z'\\ t'\end{array}\right)=\left(\begin{array}{rrrr} \frac{1}{2}&\frac{1}{2}&0&\frac{1}{2}\\ \frac{1}{2}&-\frac{1}{2}&1&-\frac{1}{2}\\ 0&0&1&0\\ 0&0&0&1\end{array}\right)\left(\begin{array}{c} x\\ y\\ z\\ t\end{array}\right)\]
% 	{\em obtenemos} \[Q(x,y,z,t)=(x'+y')(x'-y')-z^{'2}=x^{'2}-y^{'2}-z^{'2}\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% 
% %******************************************INVARIANTES LINEALES DE UNA FORMA CUADRÁTICA****************************************
% 
% \section{Invariantes lineales de una forma cuadrática}
% {\em Como sabemos, las matrices asociadas a la misma forma cuadrática en distintas bases son congruentes, el problema consiste en dada una matriz simétrica $A$, determinar una matriz diagonal $D$ congruente con $A$.\\[2mm]
% 
% Un primer método para obtenerla es la diagonalización por semejanza ortogonal, recordar que cada matriz simétrica es diagonalizable por semejanza ortogonal, es decir, existe una matriz ortogonal $P$ de forma que} \[D=P^tAP.\]
% 
% \teo {\em Sea $E$ un espacio vectorial sobre $\m{R}$ de dimensión finita y sea $Q:E\to \m{R}$ su forma cuadrática asociada. Existe una base de $E$ para la cual la matriz asociada a $Q$ es diagonal.\\[2mm]
% 
% Veamos como para una forma cuadrática real $Q$, el número de elementos positivos y de elementos negativos en la forma diagonal es un {\bf invariante} de $Q$, esto es: en el proceso de diagonalización por congruencia el resultado es esencialmente independiente del camino seguido.}
% 
% 
% %******************************************LEY DE INCERCIA DE SYLVESTER***************************************************
% 
% \subsection{ Ley de inercia de Sylvester}
% 
% \teo[\bf Ley de inercia de Sylvester] {\em Todas las matrices diagonales congruentes con una misma matriz real y simétrica tienen el mismo número de elementos positivos, el mismo número de elementos negativos, y el mismo número de elementos nulos.\\[2mm]
% 
% {\bf Demostración:}\\[2mm]
% Sean dos matrices diagonales congruentes con una misma matriz $A$, que expresaremos de la siguiente manera, siendo todos los $\alpha_j$ y $\beta_j$ positivos: \[D=diag(\alpha_1,\ldots,\alpha_p,-\alpha_{p+1},\ldots,-\alpha_r,0,\ldots,0)\] y \[D'=diag(\beta_1,\ldots,\beta_q-\beta_{q+1},\ldots,-\beta_r,0, \ldots,0)\] donde $r$ respresenta el rango de la matriz $A$.\\[2mm]
% 
% Nuestro objetivo ahora es mostrar que $p=q$.\\[2mm]
% 
% Sean \[(u_1,u_2,\ldots,u_n)\quad \mbox{y} \quad (v_1,v_2,\ldots,v_n)\]
% las bases en las que la forma cuadrática de $A$ se expresa, respectivamente, mediante $D$ y $D'$.
% 
% Tenemos que 
% \[f(u_j)=\alpha_j>0\quad \mbox{para }j=1,2,\ldots,p;\qquad f(u_j)=-\alpha_j<0\quad \mbox{para }j=p+1,\ldots,r;\]
% \[f(v_j)=\beta_j>0\quad \mbox{para }j=1,2,\ldots,q;\qquad f(v_j)=-\beta_j<0\quad \mbox{para }j=q+1,\ldots,r;\]  
% 
% Ahora consideremos los subespacios de $E$ \[L=\C{L}\{u_1,u_2,\ldots,u_p\}\quad \mbox{ y }\quad M=\C{L}\{v_{q+1},\ldots,v_n\}.\]
% Para todo $x\in L-\{0\}$, se verifica que $f(x)>0$; para todo $x\in M$, se tiene que $f(x)<0$; por tanto, el único elemento común a ambos es el $0$, luego se tiene entonces que \[L\cap M=\{0\}\] y, por consiguiente
% \[\dim (L\oplus M)=\dim L+\dim M=p+n-q.\]
% Ahora bien, como esta dimensión no puede ser mayor que $n$, se deduce que \[p-q\leq 0\] es decir, \[p\leq q.\]
% 
% Intercambiando los papeles de $D$ y $D'$, se deduce análogamente que \[q\leq p\] y se concluye finalmente que \[p=q\]
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% 
% %*********************************************RANGO Y SIGNATURA********************************************************
% 
% \subsection{Rango y signatura}
% \defi {\em Dada una forma cuadrática $Q$, se define su {\bf signatura}, y se denota por $\sigma(Q)$\footnote{Algunas veces la signatura de una forma cuadrática $Q$ se la denota también como {\bf sg}($Q$).}, como el número de coeficientes positivos, menos el número de negativos, en cualquier forma diagonal de la misma.
% 
% Es decir llamaremos {\bf signatura} de la forma cuadrática real $Q$ al par \[\sigma(Q)=(p,q)\] donde $p$ es el número de elementos positivos \emph{(valores propios positivos de la matriz $Q$)} y $q$ el de negativos \emph{(valores propios negativos)} en una forma diagonal de $Q$.
% 
% Por otra parte, el rango de $Q$ es igual al número de filas no nulas de su forma diagonal y por tanto} \[rg(Q)=p+q.\]
% 
% 
% %********************************************CLASIFICACIÓN DE FORMAS CUADRÁTICAS********************************************
% 
% \subsection{Clasificación de formas cuadráticas}
% {\em Ahora veremos cómo se puede analizar el signo que toma una forma cuadrática real examinando una de sus matrices asociadas. Para ello comenzamos con las siguientes definiciones:}
% 
% 
% %***********************************************CLASIFICACIÓN POR MATRICES***************************************************
% 
% \defi {\em Sea $A\in \C{M}(\m{R})_{n\times n}$ se dice que: 
% \begin{itemize}
% 	\item [a)] A es {\bf definida positiva}, si y sólo si $\vec{x}^tA\vec{x}>0$, para todo $\vec{x}\in E$, $\vec{x}\neq 0$.
% 	\item [b)] A es {\bf definida negativa}, si y sólo si $\vec{x}^tA\vec{x}<0$, para todo $\vec{x}\in E$, $\vec{x}\neq 0$.
% 	\item [c)] A es {\bf semidefinida positiva}, si y sólo si $\vec{x}^tA\vec{x}\geq 0$, para todo $\vec{x}\in E$, $\vec{x}\neq 0$ y existe $\vec{x}\in E$, $\vec{x}\neq 0$ tal que $\vec{x} A\vec{x}=0$.
% 	\item [d)] A es {\bf semidefinida negativa}, si y sólo si $\vec{x}^tA\vec{x}\leq 0$, para todo $\vec{x}\in E$, $\vec{x}\neq 0$ y existe $\vec{x}\in E$, $\vec{x}\neq 0$ tal que $\vec{x} A\vec{x}=0$.
% 	\item [e)] A es {\bf no definida } o {\bf indefinida} si no se verifica ninguna de las condiciones anteriores.
% \end{itemize}
%  
% De este modo, surge de manera natural la correspondiente clasificación de las formas cuadráticas que recogemos, análogamente, en la siguiente clasificación.}\\[3mm]
% 
% 
% %***********************************************CLASIFICACIÓN POR LA FORMA CUADRÁTICA****************************************
% 
% \defi {\em Se dice que una forma cuadrática real $Q:E\to \m{R}$ es:
% \begin{itemize}
% 	\item [a)] {\bf definida positiva}, si y sólo si $Q(x)>0$, para todo $x\in E$, $x\neq 0$.
% 	\item [b)] {\bf definida negativa}, si y sólo si $Q(x)<0$, para todo $x\in E$, $x\neq 0$.
% 	\item [c)] {\bf semidefinida positiva}, si y sólo si $Q(x)\geq 0$, para todo $x\in E$, $x\neq 0$ y existe $x\in E$, $x\neq 0$ tal que $Q(x)=0$.
% 	\item [d)] {\bf semidefinida negativa}, si y sólo si $Q(x)\leq 0$, para todo $x\in E$, $x\neq 0$ y existe $x\in E$, $x\neq 0$ tal que $Q(x)=0$.
% 	\item [e)] {\bf no definida o indefinida}, si no se verifica ninguna de las condiciones anteriores.
% \end{itemize}}
% 
% 
% %*********************************************CLASIFICACIÓN POR AUTOVALORES**************************************************
% 
% \subsubsection*{Criterio de los autovalores\footnote{Autovalores o valores propios}}
% {\em Sea \[Q(x)=\vec{x}^t A \vec{x}\] la expresión matricial de una forma cuadrática $Q$. Se tiene }
% \defi {\em Dada una matriz $A$ simétrica y cuadrada 
% \begin{itemize}
% 	\item [a)] $A$ es {\bf definida positiva} si y sólo si todos los autovalores de $A$ son estrictamente positivos.
% 	\item [b)] $A$ es {\bf definida negativa} si y sólo si todos los autovalores de $A$ son estrictamente negativos.
% 	\item [c)] $A$ es {\bf semidefinida positiva} si y sólo si todos los autovalores de $A$ son positivos o nulos.
% 	\item [d)] $A$ es {\bf semidefinida negativa} si y sólo si todos los autovalores de $A$ son negativos o nulos.
% 	\item [e)] $A$ es {\bf no definida o indefinida} si y sólo si $A$ posee autovalores positivos o negativos. 
% \end{itemize}}
%   
% %****************************************CLASIFICACIÓN-OBSERVACIÓN- POR LA SIGNATURA*****************************************  
%   
% \obs {\em Una forma cuadrática no nula de $E$, de rango $r$ y signatura $\sigma$, es:
% \begin{itemize}
% 	\item definida positiva \quad $\Leftrightarrow$ \quad $r=\sigma=n$.
% 	\item definida negativa \quad $\Leftrightarrow$ \quad $r=\sigma<n$.
% 	\item semidefinida positiva \quad $\Leftrightarrow$ \quad  $r=-\sigma=n$.
% 	\item semidefinida negativa \quad $\Leftrightarrow$ \quad $r=-\sigma<n$.
% 	\item no definida o indefinida \quad $\Leftrightarrow$ \quad $|\sigma|<r$.
% \end{itemize}
% 
% A veces el cálculo de los valores propios no es fácil, por ejemplo si la matriz es de orden mayor o igual a $3$ y con valores propios no enteros es imposible aplicar Ruffini para su cálculo. Veamos ahora un nuevo método basado en transformaciones elementales que resuelven este problema.}
% 
% \pro {\em Dos matrices cuadradas de igual orden $A$ y $C$ son congruentes entre sí, y sólo si, una puede obtenerse a partir de la otra haciendo transformaciones elementales, las mismas por filas que por columnas.\\[2mm]
% 
% Por tanto, debemos de desarrollar un algoritmo para obtener a partir de $A$ una matriz diagonal por medio de transformaciones elementales de este tipo. Puesto que toda matriz congruente con una matriz simétrica es simétrica y las matrices diagonales son simétricas, nuestra matriz de partida $A$ a de ser simétrica.}
% 
% \pro {\em Toda matriz simétrica real es congruente a una matriz diagonal en cuya diagonal sólo aparecen los valores $0$, $1$ y $-1$.}
% 
% \cor {\em Sea $Q$ una forma cuadrática real con matriz asociada $A$, entonces:
% \begin{itemize}
% 	\item $Q$ es definida positiva si y sólo si $A$ es congruente a la matriz identidad $I_n$.
% 	\item $Q$ es definida negativa si y sólo si $A$ es congruente a la matriz identidad $-I_n$.
% \end{itemize}}
% 
% 
% %***************************************************CRITERIO DE SYLVESTER***********************************************
% 
% \subsection{Criterio de Sylvester}
% 
% \teo[\bf Criterio de Sylvester para matrices definidas positivas] {\em Sea $A\in \C{M}(\m{R})_{n\times n}$ simétrica;
% \[A ~\mbox{ es definida positiva }~\Leftrightarrow \quad\det\left(\begin{array}{ccc} a_{11}&\ldots&a_{1k}\\ \vdots&\ddots&\vdots\\ a_{1k}&\ldots &a_{kk} \end{array}\right)>0\qquad \forall~k=1,2,\ldots,n.\]
% Es decir, que sean positivos todos los menores de la matriz $A$.\\[2mm]
% 
% {\bf Demostración:}\\[2mm]
% \indent \fbox{$\Rightarrow$} Si $A$ es definida positiva, también lo es, para $k=1,2,\ldots,n$, la forma cuadrática de $\m{R}^k$.
% \[(x_1,\ldots,x_k)\left(\begin{array}{ccc} a_{11}&\ldots&a_{1k}\\ \vdots&\ddots&\vdots\\ a_{1k}&\ldots &a_{kk}\end{array}\right)\left(\begin{array}{c} x_1\\ \vdots\\ x_k\end{array}\right)=(x_1,\ldots,x_k,0,\ldots,0)A\left(\begin{array}{c} x_1\\ \vdots\\ x_k\\ 0\\ \vdots\\ 0\end{array}\right)\] 
% el determinante de cuya matriz ha de ser, por tanto, positivo.\\[2mm]
% 
% \fbox{$\Leftarrow$} Lo probaremos por inducción en $n$. Para $n=1$, el resultado es trivialmente cierto. Supongamos que es cierto para $n$ y sea 
% \[A_{n+1}=\left(\begin{array}{cccc} a_{11}&\ldots&a_{1n}&a_{1~n+1}\\ \vdots&\ddots&\vdots&\vdots\\ a_{1n}&\ldots&a_{nn}&a_{n~n+1}\\ a_{1~n+1}&\ldots&a_{n~n+1}&a_{n+1~n+1}\end{array}\right)\] 
% satisfaciendo que $\det A_k>0$ para $k=1,2,\ldots,n+1$, en donde 
% \[A_k=\left(\begin{array}{ccc} a_{11}&\ldots&a_{1k}\\ \vdots&\ddots&\vdots\\ a_{1k}&\ldots &a_{kk} \end{array}\right)\]
% Por hipótesis de inducción, la matriz $A_n$ es definida positiva, o lo que es lo mismo, congruente con $I_n$. Si $P$ es tal que \[P^tA_nP=I_n\] podemos escribir \[\tilde{P}^tA_{n+1}\tilde{P}=\left(\begin{array}{cc} P^t&0\\ 0&1\end{array}\right)A_{n+1}\left(\begin{array}{cc} P^t&0\\ 0&1\end{array}\right)=\left(\begin{array}{cccc} 1&\ldots&0&\tilde{a}_{1~n+1}\\ \vdots&\ddots&\vdots&\vdots\\ 0&\ldots&1&\tilde{a}_{n~n+1}\\ \tilde{a}_{1~n+1}&\ldots&\tilde{a}_{n~n+1}&\tilde{a}_{n+1~n+1}\end{array}\right)\]
% 
% Efectuando sobre la última matriz las operaciones elementales por filas \[F'_{n+1}=F_{n+1}-\sum_{i=1}^n \tilde{a}_{i~n+1}F_i\]
% y las mismas operaciones por columnas, obtenemos la matriz 
% \[B=\left(\begin{array}{cccc} 1&\ldots&0&0\\ \vdots&\ddots&\vdots&\vdots\\ 0&\ldots&1&0\\ 0&\ldots&0&b\end{array}\right)\]
% donde \[b=\tilde{a}_{n+1~n+1}-\sum_{i=1}^n \tilde{a}^2_{i~n+1}\]
% Como la matriz $B$ es congruente con $A_{n+1}$, sea $Q$ tal que \[B=Q^t A_{n+1} Q\] y concluímos finalmente que 
% \[b=\det B=(\det Q)^2 \det A_{n+1}>0\] por lo que $B$ \emph{(y por tanto $A_{n+1}$)} es definida positiva.
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% \teo[\bf Criterio de Sylvester para matrices definidas negativas] {\em Sea $A\in \C{M}(\m{R})_{n\times n}$ simétrica:
% \[A ~\mbox{ es definida negativa }~\Leftrightarrow \quad(-1)^k\det\left(\begin{array}{ccc} a_{11}&\ldots&a_{1k}\\ \vdots&\ddots&\vdots\\ a_{1k}&\ldots &a_{kk} \end{array}\right)>0\qquad \forall~k=1,2,\ldots,n.\] 
% {\bf Demostración:}\\[2mm]
% \begin{center}
% $A$ es definida negativa \quad $\Leftrightarrow$\quad $-A$ es definida positiva es decir:
% \end{center}
%  \[\det (-A_k)=(-1)^k\det A_k\]
% \begin{flushright}
% $\blacksquare$
% \end{flushright}}
% 
% \cor {\em Si $\det A_k\neq 0$ y no se cumple ninguna de los dos teoremas anteriores, entonces $Q$ es no definida o indefinida.}
% \cor {\em $Q$ es semidefinida positiva si se cumple $\det A_k>0$, para cada $k=1,2,\ldots,n-1$ y $\det A=0$.}
% \cor {\em $Q$ es semidefinida negativa si se cumple $(-1)^k\det A_k>0$, para cada $k=1,2,\ldots,n-1$ y $\det A=0$.}
% \cor {\em Si $\det A_k\neq 0$, para cada $k=1,2,\ldots,n-1$ y $\det A=0$ y no se cumple los dos últimos corolarios entonces $Q$ es indefinida. }
% 
% 
% %***************************************************FORMAS SESQUILINEALES****************************************************
% 
% \section{Formas sesquilineales}
% \defi {\em Sea $E$ un espacio vectorial sobre $\m{C}$, se denomina {\bf forma sesquilineal} sobre $E$ a toda aplicación
% \[f:E\times E\to \m{C}\]
% tal que
% \begin{enumerate}
% 	\item $f(u+v,w)=f(u,w)+f(v,w)$,\qquad $\forall u,v,w\in E$.
% 	\item $f(u,v+w)=f(u,v)+f(u,w)$,\qquad $\forall u,v,w\in E$.
% 	\item $f(\alpha u,v)=\alpha f(u,v)$,\qquad $\forall u,v\in E$,\quad $\forall \alpha\in \m{C}$.
% 	\item $f(u,\beta v)=\bar{\beta} f(u,v)$,\qquad $\forall u,v\in E$,\quad $\forall \beta\in \m{C}$.
% \end{enumerate}}
%  
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item {\em Sea $E=\m{C}^2$, un espacio vectorial sobre $\m{C}$, y la forma $f$ definida por
% 	\[\begin{array}{rccl} f:&\m{C}^2\times \m{C}^2&\to& \m{C}\\ &(x,y)&\mapsto&x_1\bar{y_1}+3x_1\bar{y_2}-x_2\bar{y_1}+2x_2\bar{y_2}\end{array}\]
% 	¿ $f$ es una forma sesquilineal ?.\\[2mm]
% 	
% 	En efecto: Veamos por ejemplo que se verifica lo siguiente.\\[2mm]
% 	$\forall x,y,z\in \m{C}^2$, se tiene
% 	\begin{eqnarray*}
% 	f((x_1,x_2)+(y_1,y_2),(z_1,z_2))&=&f((x_1+y_1,x_2+y_2),(z_1,z_2))\\
% 	&=&(x_1+y_1)\bar{z_1}+3(x_1+y_1)\bar{z_2}-(x_2+y_2)\bar{z_1}+2(x_2+y_2)\bar{z_2}\\
% 	&=&x_1\bar{z_1}+3x_1{z_2}-x_2\bar{z_1}+2x_2\bar{z_2}+y_1\bar{z_1}+3y_1\bar{z_2}-y_2\bar{z_1}+2y_2\bar{z_2}\\
% 	&=&f((x_1,x_2),(z_1,z_2))+f((y_1,y_2),(z_1,z_2))
% 	\end{eqnarray*}
% 	
% 	y además\\[2mm]
% 	$\forall \alpha\in\m{C}$, $\forall x,y\in \m{C}^2$, se tiene
% 	\begin{eqnarray*}
% 	f((x_1,x_2),\alpha (y_1,y_2))&=&f((x_1,x_2),(\alpha y_1,\alpha y_2))\\
% 	&=&x_1\overline{(\alpha y_1)} +3x_1\overline{(\alpha y_2)} -x_2\overline{(\alpha y_1)} +2x_2\overline{(\alpha y_2)}\\
% 	&=&\bar{\alpha}(x_1\bar{y_1}+3x_1\bar{y_2}-x_2\bar{y_1}+2x_2\bar{y_2})\\ç
% 	&=&\bar{\alpha}f((x_1,x_2),(y_1,y_2))	
% 	\end{eqnarray*}}	
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% \end{enumerate}
% 
% \obs {\em Dado un espacio vectorial $E=\m{K}^n$ sobre $\m{K}$ de dimensión $n$, y un conjunto de escalares $\{\alpha_{ij}~/~\alpha_{ij}\in \m{K},\quad i,j=1,2,\ldots, n\}$. Entonces la aplicación \[f:E\times E\to \m{K}\] definida por \[(u,v)\mapsto \sum_{i,j=1}^n \alpha_{ij} x_i\bar{y_1}\]
% es una forma bilineal.\\[2mm]
% 
% Es fácil comprobar que si $\m{K}=\m{R}$, las aplicaciones antes mencionadas resultan ser formas bilineales.\\[2mm]
% 
% Por tanto, podemos considerar a las formas sesquilineales análogas a las formas bilineales.}
% 
% \section{Expresión matricial de una forma sesquilineal}
% {\em Sea $E$ un espacio vectorial sobre $\m{K}$ de dimensión $n$, Si $B=\{e_1,e_2,\ldots,e_n\}$ es una base ordenada de $E$ y $f$ una forma sesquilineal en $E$ además si $x,y\in E$, se puede escribir $f$ de la siguiente manera:\\
% Dado que $x,y\in E$, se tiene que 
% \[x=\sum_{i=1}^n x_i e_i \qquad \mbox{ y }\qquad y=\sum_{j=1}^n y_je_j\]
% por tanto 
% \begin{eqnarray*}
% f(x,y)&=&f\left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j\right)\\
% &=&\sum_{i=1}^n x_i f\left(e_i,\sum_{j=1}^n y_je_j\right)\\
% &=&\sum_{i=1}^n x_i \sum_{j=1}^n \overline{y_j} f(e_i,e_j)\\
% &=&\sum_{i=1}^n \sum_{j=1}^n x_i f(e_i,e_j) \overline{y_j}\\
% &=&[x]_B^t A \overline{[y]}_B
% \end{eqnarray*}
%  en donde}
%  \[A=\left(\begin{array}{cccc} f(e_1,e_1)&f(e_1,e_2)&\ldots&f(e_1,e_n)\\ f(e_2,e_1)&f(e_2,e_2)&\ldots&f(e_2,e_n)\\ \vdots&\vdots&\ldots&\vdots\\ f(e_n,e_1)&f(e_n,e_2)&\ldots&f(e_n,e_n)\end{array}\right)\]
% 
% {\em La expresión \[f(x,y)=[x]_B^t A\overline{[y]}_B\] se denominada representación matricial de la forma sesquilineal respecto de la base $B$. Mientras que la matriz $A$ se denomina matriz asociada a la forma sesquilineal $f$ respecto a la base $B$.\\[2mm]
% 
% Esta representación depende de la base $B$.}\\[2mm]
% 
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item {\em Calcular la matriz asociada a la forma sesquilineal 
% 	\[\begin{array}{rccl} f:&\m{C}^2\times \m{C}^2&\to&\m{C}\\ &((x_1,x_2),(y_1,y_2))&\mapsto&x_1\bar{y_1}+3x_1\bar{y_2}-x_2\bar{y_1}+2x_2\bar{y_2}\end{array}\]
% 	respecto de la base canónica de $\m{C}^2$, $B=\{\underbrace{(1,0)}_{e_1},\underbrace{(0,1)}_{e_2}\}$.\\[2mm]
% 	\[A=\left(\begin{array}{rr} f(e_1,e_1)&f(e_1,e_2)\\ f(e_2,e_1)&f(e_2,e_2)\end{array}\right)=\left(\begin{array}{rr} 1&3\\ -1&2\end{array}\right)\]
% 	halle $f(x,y)$, donde $x=(1+i, 2i)$, $y=(0,3-i)$.\\[2mm]
% 	Dado que \[f(x,y)=[x]_B^t A\overline{[y]}_B\]
% 	se sigue que
% 	\begin{eqnarray*}
% 	f((1+i, 2i),(0,3-i))&=&(1+i, 2i)A\left(\begin{array}{c} 0\\ 3-i\end{array}\right)\\
% 	&=&(1+i, 2i)\left(\begin{array}{rr} 1&3\\ -1&2\end{array}\right)\left(\begin{array}{c} 0\\ 3-i\end{array}\right)\\
% 	&=&2-24i. 
% 	\end{eqnarray*}}
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% \defi {\em Dos matrices $A,C\in \C{M}(\m{K})_{n\times n}$ se dicen {\bf congruentes hermíticas} si existe una matriz $P\in \C{M}(\m{K})_{n\times n}$ tal que \[B=PAP^*,\qquad \mbox{siendo}\quad P^*=\overline{P^t}\]
% 
% Dos matrices congruentes hermíticas son equivalentes y, por tanto, tienen el mismo rango.}
% 
% \defi {\em Sea $E$ un espacio vectorial de dimensión finita y sea $f$ una forma sesquilineal
% \[f:E\times E\to \m{K}\]
% entonces
% \begin{itemize}
% 	\item Se denomina rango de $f$ al rango de cualquiera de sus matrices asociadas.
% 	\item Se dice que $f$ es {\bf no degenerada } si $rg(f)=n=\dim E$.
% 	\item Se dice que $f$ es {\bf degenerada } si $rg(f)<n=\dim E$.
% \end{itemize}}
% 
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item {\em Sea $E$ un espacio vectorial sobre $\m{C}$ de $\dim =2$.
% 	\[f:E\times E\to \m{C}\]
% 	definida por 
% 	\[f(x,y)=3x_1\bar{y_1}+(1+i)x_2\bar{y_2}-ix_1\bar{y_2}+(2-i)x_2\bar{y_1}\]
% 	Calcule el rango de $f$ y el determinante de la matriz asociada a $f$.\\[2mm]
% 	\[f(x,y)=(x_1,x_2)\left(\begin{array}{cc} 3&-i\\ 2-i&1+i\end{array}\right)\left(\begin{array}{c} \bar{y_1}\\ \bar{y_2}\end{array}\right)\]
% 	Por tanto 
% 	\[H=\left(\begin{array}{cc} 3&-i\\ 2-i&1+i\end{array}\right)\]
% 	es la matriz asociada a $f$.\\[2mm]
% 	\[\det H=3(1+i)+i(2-i)=4+5i\neq 0\]
% 	además
% 	\[rg(H)=2\]
% 	Por lo cual, $f$ es no degenerada.}
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% \section{Formas hermíticas}
% \defi {\em Se denomina {\bf forma hermítica} sobre $E$ a toda forma sesquilineal $f$ sobre $E$ con simetría hermítica, es decir, tal que 
% \[f(x,y)=\overline{f(y,x)},\qquad \forall~x,y\in E\]}
% 
% \obs {\em 1.\quad Si $f$ es hermítica, se verifica
% \[f(x,x)=\overline{f(x,x)}\quad \Rightarrow\quad f(x,x)\in\m{R},\qquad \forall~x\in E\]
%  
% 2.\quad Si $\m{K}=\m{R}$, toda forma hermítica es {\bf bilineal simétrica}, es decir, es bilineal y además
% \[f(x,y)=f(y,x),\qquad \forall x,y\in E\]} 
% 
% {\bf Ejemplo:}
% \begin{enumerate}
% 	\item {\em La forma sesquilineal \[f:\m{C}^2\times \m{C}^2\to \m{C}\]
% 	tal que \[f((x_1,x_2),(y_1,y_2))=2x_1\bar{y_1}+(1+i)x_1\bar{y_2}+(1-i)x_2\bar{y_1}\]
% 	es una forma hermítica.\\[2mm]
% 	En efecto \[f(y,x)=2y_1\bar{x_1}+(1+i)y_1\bar{x_2}+(1-i)y_2\bar{x_1}\]
% 	Por lo tanto} \[\overline{f(y,x)}=2x_1\bar{y_1}+(1+i)x_1\bar{y_2}+(1-i)x_2\bar{y_1}\]
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
% 
% \teo {\em Sea $E$ un espacio vectorial y $f:E\times E\to \m{K}$ una forma sesquilineal. Las siguientes afirmaciones son equivalentes:
% \begin{enumerate}
% 	\item $f$ es hermítica.
% 	\item Toda matriz asociada a la forma verifica: $A^*=A$.
% 	\item Todos los elementos de la diagonal principal de la matriz asociada a la forma son números reales. 
% \end{enumerate}}
% 
% \defi {\em Una matriz $A\in \C{M}(\m{K})_{n\times n}$ se dice hermítica si verifica que \[A^*=A.~\footnote{Donde $A^*=\overline{A^t}.$}\]}
% 
% \teo {\em Las matrices hermíticas verifican:
% \begin{enumerate}
% 	\item Sea $A\in \C{M}(\m{R})_{n\times n}$, $A$ es hermítica\quad $\Leftrightarrow$\quad $A$ es simétrica.
% 	\item Sea $A\in \C{M}(\m{K})_{n\times n}$,
% \begin{enumerate}
% 	\item $A$ es hermítica \quad $\Leftrightarrow$\quad $A^*$ es hermítica.
% 	\item $A$ es hermítica \quad $\Rightarrow$\quad $\forall n\in \m{N}$, $A^n$ es hermítica.
% 	\item Si $A$ es no singular, $A$ es hermítica \quad $\Leftrightarrow$\quad $A^{-1}$ es hermítica. 
% \end{enumerate}
% \end{enumerate}}
% 
% \defi {\em Sea $E$ un espacio vectorial sobre $\m{K}$. Denominaremos {\bf forma cuadrática} sobre $\m{K}$ a toda aplicación 
% \[Q:E\to \m{R}\]
% que cumple:
% \[Q(x)=Q(x,x),\qquad \forall x\in E\]
% siendo $f$ una forma hermítica sobre $E$.\\[2mm]
% 
% Obsérvese que en principio $f$, podría ser una forma sesquilineal cualquiera, no necesariamente hermítica.}
% 
% \obs {\em De la definición anterior, podemos establecer lo siguiente:
% \begin{enumerate}
% 	\item $Q(x)=f(x,x)\in \m{R}$, \qquad $\forall~x\in E$.
% 	\item $Q(\alpha x)=\alpha^2 Q(x)$, \qquad $\forall~x\in E$, $\forall~\alpha\in \m{K}$.
% 	\item Toda forma hermítica $f$ induce una forma cuadrática $Q$, y recíprocamente, dada una forma cuadrática $Q$ puede determinarse la única forma hermítica $f$.
% 	\end{enumerate}}
% 
% \defi {\em La forma hermítica única inducida por una forma cuadrática se denominan {\bf forma polar} asociada a $Q$. Definida como:
% \[f(x,y)=\frac{1}{4}[Q(x+y)-Q(x-y)]+\frac{1}{4}[Q(x+iy)-Q(x-iy)]\]
% 
% La expresión anterior, algunas veces es conocido también como: {\bf Identidad de Polarización}.}
% 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
% \section{Ejercicios Resueltos:}
% \begin{enumerate}
% 	\item {\em Comprobar que las siguientes aplicaciones son o no bilineales y en las que resulten serlo, dar la matriz asociada en la base canónica. Decidir también si las formas bilineales son simétricas o antisimétricas.}\\[2mm]
% 	\begin{itemize}
% 	\item {\em Sea $f:\m{R}^2\times \m{R}^2\to \m{R}$ definida por 
% 	\[f((x_1,x_2),(y_1,y_2))=x_1x_2+y_1y_2\]
% 	Si ahora tratamos de escribir la matriz suponiendo que es bilineal obtenemos:
% 	\[A=\left(\begin{array}{cc} f((1,0),(1,0))&f((1,0),(0,1))\\ f((0,1),(1,0))&f((0,1),(0,1))\end{array}\right)=\left(\begin{array}{cc} 0&0\\ 0&0 \end{array}\right)\]
% 	Si fuese bilineal tendría que cumplirse
% 	\[f((x_1,x_2),(y_1,y_2))=(x_1,x_2) A \left(\begin{array}{c} y_1\\ y_2\end{array}\right)=0\]
% 	Pero esto no es cierto, luego NO es BILINEAL.\\[2mm]
% 	Otra forma de verlo es que: }
% 	\[f((1,0)+(0,1),(0,0))=1\neq 0=f((1,0),(0,0))+f((0,1),(0,0))\]
% 	
% 	\item {\em Sea $f:\wp_2[\m{R}]\times \wp_2[\m{R}]\to \m{R}$, definida por
% 	\[f(p,q)=p(1)q(-1)-p(-1)q(1)\]
% 	Veamos si es bilineal utilizando la definición. Sean $p,q,p_1,p_2,q_1,q_2\in \wp_2[\m{R}]$ y $\alpha, \beta\in \m{R}$. Tenemos }
% 	\begin{eqnarray*}
% 	f(\alpha p_1+\beta p_2, q)&=&(\alpha p_1(1)+\beta p_2(1))q(-1)-(\alpha p_1(-1)+\beta p_2(-1))q(1)\\
% 	&=&\alpha p_1(1)q(-1) -\alpha p_1(-1)q(1)+\beta p_2(1)q(-1) -\beta p_2(-1)q(1)\\
% 	&=&\alpha f(p_1,q) +\beta f(p_2,q)
% 	\end{eqnarray*}
% 	{\em Análogamente vemos que:
% 	\[f(p,\alpha q_1+\beta q_2)=\alpha f(p,q_1)+\beta f(p,q_2)\]
% 	y por tanto ES BILINEAL.\\[2mm]
% 	Calculamos la matriz de la aplicación en la base canónica $\{1,x,x^2\}$.\\[2mm]
% 	La matriz es 
% 	\[A=\left(\begin{array}{ccc} f(1,1)&f(1,x)&f(1,x^2)\\ f(x,1)&f(x,x)&f(x,x^2)\\ f(x^2,1)&f(x^2,x)&f(x^2,x^2)\end{array}\right)=\left(\begin{array}{rrr} 0&-2&0\\ 2&0&2\\ 0&-2&0\end{array}\right)\]
% 	Vemos que la matriz es antisimétrica y por tanto la aplicación bilineal ES ANTISIMÉTRICA.}
% 	\end{itemize}
% 	
% 	\item {\em Dada la forma bilineal $f$ definida en $\m{R}^3$
% 	\[f((x_1,x_2,x_3),(y_1,y_2,y_3))=x_1y_1-x_2y_2+2x_1y_3\]
% 	construya la matriz de $f$ en la base de $\m{R}^3$ \[B=\{(1,1,0),(0,1,1),(1,1,1)\}\]
% 	y muestre que $f$ no es simétrica, dando dos vectores $x,y\in \m{R}^3$ tales que \[f(x,y)\neq f(y,x)\]
% 	La matriz que nos piden es 
% 	\[A=\left(\begin{array}{ccc} f((1,1,0),(1,1,0))&f((1,1,0),(0,1,1))&f((1,1,0),(1,1,1))\\ f((0,1,1),(1,1,0))&f((0,1,1),(0,1,1))&f((0,1,1),(1,1,1))\\ f((1,1,1),(1,1,0))&f((1,1,1),(0,1,1))&f((1,1,1),(1,1,1))\end{array}\right)=\left(\begin{array}{rrr} 0&1&2\\ -1&-1&-1\\ 0&1&2\end{array}\right)\]  
% 	 Otra forma de calcularla es obtener primero su matriz de $f$ respecto a la base canónica $\emph{(es más simple)}$ y despúes utilizar la matriz cambio de base $B$ a la canónica.
% 	 \[\left(\begin{array}{rrr} 1&1&0\\ 0&1&1\\ 1&1&1\end{array}\right)\left(\begin{array}{rrr} 1&0&-2\\ 0&-1&0\\ 0&0&0\end{array}\right) \left(\begin{array}{rrr} 1&1&0\\ 0&1&1\\ 1&1&1\end{array}\right)^t=\left(\begin{array}{rrr} 0&1&2\\ -1&-1&-1\\ 0&1&2\end{array}\right)\]
% 	 No es simétrica por que no lo es su matriz. Por ejemplo}
% 	 \[f((1,1,0),(0,1,1))\neq f((0,1,1),(1,1,0))\] 
% 	 
% 	 \item {\em En $\m{R}^3$ hallar la matriz con respecto a la base canónica $\{e_1,e_2,e_3\}$ de una aplicación bilineal $f$ tal que verifique lo siguiente:
%    \begin{itemize}
% 	   \item $f$ es simétrica.
% 	   \item $f(e_2,e_2)=f(e_3,e_3)$.
% 	   \item Los vectores $e_1$ y $e_2$ son conjugados.
% 	   \item $f(xe_1+ye_2,e_3)=y$.
% 	   \item La forma cuadrática asociada a $f$ y restringida al subespacio $\C{L}\{e_1,e_2\}$ tiene rango $1$ y restringida al subespacio $\C{L}\{e_2,e_3\}$ es semidefinida negativa. 
%    \end{itemize}
%    
%    Sea $F$ la matriz que buscamos. Vamos imponiendo las condiciones que nos dan. Recordemos que el término en la posición $i,j$ de $F$ es $F_{ij}=f(e_i,e_j)$.\\[2mm]
%    Por ser $f$ simétrica, la matriz $F$ es simétrica:
%    \[F=\left(\begin{array}{ccc} a&b&c\\ b&d&e\\ c&e&f\end{array}\right)\]
%    
%    Como $f(e_2,e_2)=f(e_3,e_3)$ entonces $d=f$.\\[2mm]
%    Que $e_1$ y $e_2$ sea conjugados significa que $f(e_1,e_2)=0$, luego $b=0$.\\[2mm]
%    Como $f(xe_1+ye_2,e_3)=y$, para $x=1$, $y=0$ vemos que $f(e_1,e_3)=0$ y para $x=0$, $y=1$ vemos que \[f(e_2,e_3)=1\] por tanto $c=0$ y $e=1$.\\[2mm]
%    Tenemos ahora una matriz
%    \[F=\left(\begin{array}{ccc} a&0&0\\ 0&d&1\\ 0&1&d\end{array}\right)\]
%    La matriz de la restricción de $f$ a $\C{L}\{e_1,e_2\}$ es: 
%    \[\left(\begin{array}{cc} a&0\\ 0&d\end{array}\right)\]
%    Para que tenga el rango $1$, ha de cumplirse $a=0$ y $d\neq 0$ ó $a\neq 0$ y $d=0$.\\[2mm]
%    La restricción a $\C{L}\{e_1,e_2\}$ es:
%    \[\left(\begin{array}{cc} d&1\\ 1&d\end{array}\right)\]
%    Para que sea semidefinida su determinante debe ser $0$. Luego $d^2-1=0$ y $d=\pm 1$. Pero si $d=1$ queda:
%    \[\left(\begin{array}{cc} 1&1\\ 1&1\end{array}\right)\quad \to \quad \left(\begin{array}{cc} 1&0\\ 0&0\end{array}\right)\]
%    y es semidefinida positiva.\\[2mm]
%    Si $d=-1$ queda:
%    \[\left(\begin{array}{rr} -1&1\\ 1&-1\end{array}\right)\quad \to \quad \left(\begin{array}{rr} -1&0\\ 0&0\end{array}\right)\]
%    y es semidefinida negativa.\\[2mm]
%    Deducimos que $d=-1$ y $a=0$ y la matriz $F$ es definitiva es:}
%    \[F=\left(\begin{array}{rrr} 0&0&0\\ 0&-1&1\\ 0&1&-1\end{array}\right)\]
%     
%    \item {\em Consideremos la forma cuadrática $\varphi$ de $\m{R}^4$ que en la base canónica viene dada por la matriz:
%    \[A=\left(\begin{array}{rrrr} 0&1&-1&0\\ 1&0&0&-1\\ -1&0&0&-1\\ 0&-1&-1&0\end{array}\right)\]
%    Calcule el rango y la signatura de $\varphi$.\\[2mm]
%    Diagonalizamos la matriz mediante operaciones elementales en fila y sus simétricas en columnas.
%    \[\left(\begin{array}{rrrr} 0&1&-1&0\\ 1&0&0&-1\\ -1&0&0&-1\\ 0&-1&-1&0\end{array}\right)\to \left(\begin{array}{rrrr} 1&1&-1&-1/2\\ 1&0&0&-1\\ -1&0&0&-1\\ -1/2&-1&-1&0\end{array}\right)\to \left(\begin{array}{rrrr} 1&0&0&0\\ 0&-1&1&-1/2\\ 0&1&-1&-3/2\\ 0&-1/2&-3/2&-1/4\end{array}\right)\]
%     \[\to \left(\begin{array}{rrrr} 1&0&0&0\\ 0&-1&0&0\\ 0&0&0&-2\\ 0&0&-2&0\end{array}\right)\to \left(\begin{array}{rrrr} 1&0&0&0\\ 0&-1&0&0\\ 0&0&1&-2\\ 0&0&-2&0\end{array}\right)\to \left(\begin{array}{rrrr} 1&0&0&0\\ 0&-1&0&0\\ 0&0&1&0\\ 0&0&0&-4\end{array}\right)\]
%     Por tanto el rango es $rg(\varphi)=4$ y su signatura $\sigma(\varphi)=(2,2)$.}
%     
%    \item {\em Sobre el espacio real de la matrices $2\times 2$ de elementos reales, que denotamos $\C{M}(\m{R})_{2\times 2}$, se define, la siguiente forma cuadrática:
%    \[\begin{array}{rcl} \phi:\C{M}(\m{R})_{2\times 2}&\to& \m{R}\\ A&\mapsto&\phi(A)=|A|.\end{array}\]
%    Determinar la matriz de $\phi$ en la base canónica de $\C{M}(\m{R})_{2\times 2}$.\\[2mm]
%    La forma cuadrática que nos dan a partir de las coordenadas de una matriz $A$ en la base canónica es:
%    \[\phi(x_1,x_2,x_3,x_4)=\left|\begin{array}{cc} x_1&x_2\\ x_3&x_4\end{array}\right|=x_1x_4-x_2x_3\]
%    Por tanto la matriz de esta forma cuadrática en la base canónica es:}
%    \[A=\left(\begin{array}{rrrr} 0&0&0&1/2\\ 0&0&-1/2&0\\ 0&-1/2&0&0\\ 1/2&0&0&0\end{array}\right)\]    
% \end{enumerate}
% \begin{flushright}
% $\blacktriangle$
% \end{flushright}
%  
% 	
% 
% 
% \newpage
% \section{Ejercicios Propuestos}
% \begin{enumerate}
% 	\item {\em Determinar si las siguientes funciones son o no formas bilineales. En caso afirmativo calcular su matriz en la base canónica correspondiente y determinar si la forma es bilineal simétrica:
% \begin{enumerate}
% 	\item $f:\m{R}^2\times \m{R}^2\to \m{R}$,\quad $f(x,y)=2x_1y_1+3x_2y_1-x_2y_2+3x_1y_2$.
% 	\item $f:\m{R}^2\times \m{R}^2\to \m{R}$,\quad $f(x,y)=-x_1y_1-x_2y_1+2x_2y_2+2x_1y_2$.
% 	\item $f:\m{R}^3\times \m{R}^3\to \m{R}$,\quad $f(x,y)=2x_1y_1+x_3y_3-x_1y_3-x_3y_1$.
% 	\item $f:\m{C}^3\times \m{C}^3\to \m{C}$,\quad $f(x,y)=x_1y_1+(2+i)x_2y_1+2x_2y_2+(2+i)x_1y_2+x_1y_3+x_3y_1-x_3y_3$.
% \end{enumerate}}
% \vspace{3mm}
%   \item {\em Probar que las siguientes funciones son formas bilineales: 
% \begin{enumerate}
% 	\item $f:\m{K}^n\times \m{K}^n\to \m{K}$,\quad $f(x,y)=x Ay^t$, donde $A\in \m{K}^{n\times n}$.
% 	\item $f:E\times E\to \m{K}$,\quad $f(x,y)=f_1(x).f_2(y)$, donde $E$ es un espacio vectorial y $f_1,f_2\in E^*$.
% 	\item $f:\m{K}^{m\times n}\times \m{K}^{m\times n}\to \m{K}$,\quad $f(A,B)=tr(A^tCB)$, donde $C\in \m{K}^{m\times m}$.
% \end{enumerate}}
% \vspace{3mm}
%   \item {\em Hallar una forma bilineal $f$ simétrica en $\m{R}^3$ tal que su núcleo sea $\C{N}(f)=\langle (1,2,-1)\rangle$ y $f((1,1,1),(1,1,1))<0$. Calcular la matriz de $f$ en la base canónica.}
% \vspace{3mm}  
%   \item {\em Sea $E$ un espacio vectorial sobre $\m{R}$ y $B=\{u_1,u_2,u_3\}$ una base de $E$. Sea la forma bilineal sobre $E$ \[\phi:E\times E\to \m{R}\]
%   definida por \[\phi(u_p,u_q)=\left\{\begin{array}{ccl} i^{p+q}&si&p+q~\mbox{ es par}\\ i^{p+q+1}&si&p+q~\mbox{ es impar}\end{array}\right.\qquad (i^2=-1)\]
% \begin{enumerate}
% 	\item Demuestre que $\phi$ es simétrica.
% 	\item Calcule la matriz de $\phi$ respecto de $B$.
% 	\item Hallar las coordenadas respecto de $B$ de un vector $x\in E-\{0\}$ tal que $\phi(x,x)=0$.
% \end{enumerate}}
% \vspace{3mm}  
%   \item {\em Sea $E$ el espacio vectorial de los polinomios de coeficientes reales de grado menor o igual que $2$. Es decir, 
%   \[E=\{p(x)=a_0+a_1xa_2x^2~|~a_i\in \m{R}\quad i=0,1,2.\}\]
%   Sea $\varphi$ la aplicación \[\varphi:E\times E\to \m{R}\] definida por \[\varphi(p(x),q(x))=p(0)q(0),\qquad \forall~p(x),q(x)\in E\]
%   donde $p(0)$ es el valor numérico del polinomio $p(x)$ para $x=0$.
% \begin{enumerate}
% 	\item Probar que $\varphi$ es una forma bilineal simétrica sobre $E$.
% 	\item Sea $B=\{1,x-1,x^2+1\}$ una base de $E$. Probar que 
% 	\[M_B (\varphi)=\left(\begin{array}{rrr} 1&-1&1\\ -1&1&-1\\ 1&-1&1\end{array}\right)\]
% 	y calcular una base ortogonal $B'$ de $E$, respecto de la cual $M_B(\varphi)$ sea diagonal.
% 	\item Probar que el polinomio $p(x)=2x+x^2$ es ortogonal, respecto de $\varphi$, a todos los polinomios de $E$ (tómese $B$ como base de $E$).
% \end{enumerate}}
% \vspace{3mm}  
%   \item {\em Dada la forma cuadrática \[Q(x,y,z)=x^2+3y^2+2z^2+2xy+2xz+4yz\] probar que su forma bilineal simétrica asociada define un producto escalar en $\m{R}^3$. Hallar una base ortonormal de $\m{R}^3$ respecto de este producto escalar y el subespacio vectorial de los vectores ortogonales a $(1,0,-1)$.}
% \vspace{3mm}  
%   \item {\em En $\m{R}^3$ definimos la forma cuadrática \[Q(x,y,z)=2x^2+(y-z)^2+(x+z)^2\]
% \begin{enumerate}
% 	\item Expresar matricialmente la forma bilineal simétrica asociada, y demuestre que ésta es un producto escalar.
% 	\item Calcule una base ortonormal de $\m{R}^3$ respecto de este producto escalar.
% 	\item Si $F=\{(x,y,z)\in \m{R}^3~/~x=y+z,~y=2x+z\}$, hallar $F^{\perp}$
% \end{enumerate}}
% \vspace{3mm}  
%   \item {\em Dadas las matrices \[A=\left(\begin{array}{cc} 1&2\\ 2&1\end{array}\right)\qquad B=\left(\begin{array}{rr} -3&-1\\ -1&2\end{array}\right)\]
%   encontrar una matriz regular $P$ tal que $A=P^tBP$.}
% \vspace{3mm}  
%   \item {\em Estudiar si son o no congruentes las siguientes matrices:}
%   \[A=\left(\begin{array}{cc} 2&1\\ 1&5\end{array}\right)\qquad B=\left(\begin{array}{rr} 1&1\\ 1&2\end{array}\right)\] 
% \vspace{3mm}  
%   \item {\em Para cada una de las formas bilineales simétricas reales dadas en la base canónica por las matrices siguientes, hallar una base tal que la matriz de la forma bilineal en dicha base sea diagonal con $1,-1$ y $0$ en la diagonal. Calcular su signatura y rango, decidir si es degenerada o no, definida (positiva o negativa), semidefinida (positiva o negativa) o indefinida.
% \begin{enumerate}
% 	\item $\left(\begin{array}{rrr} 1&-2&3\\ -2&6&-9\\ 3&-9&4\end{array}\right)$
% 	\item $\left(\begin{array}{rrrr} 1&1&-2&-3\\ 1&2&-5&-1\\ -2&-5&6&9\\ -3&-1&9&11\end{array}\right)$
% \end{enumerate}}
% \vspace{3mm}
%   \item {\em Sea $A\in \m{R}^{n\times n}$ una matriz simétrica. Probar que la forma bilineal que tiene a $A$ como matriz en la base canónica es definida negativa si y sólo si los signos de los menores principales van alternándose comenzando por un signo menos.}
% \vspace{3mm} 
%   \item {\em Dados $A,B\in \C{M}(\m{K})_{n\times n}$ probar que: 
%   \begin{itemize}
% 	  \item Si $A$ es invertible, entonces $rg(AB)=rg(B)$.
% 	  \item $rg(AB)\geq rg(A)+rg(B)-n$.
% 	  \item $rg(A^tA)=rg(AA^t)=rg(A)$. 
%   \end{itemize}}
%   
%   \item {\em Dadas $A,B\in \C{M}(\m{K})_{m\times n}$ probar que: \[rg(A+B)\leq rg(A)+rg(B).\]} 
%   
%   \item {\em Resolver la ecuación} \[\left|\begin{array}{ccccc} 1&x&x&\ldots&x\\ x&1&x&\ldots&x\\ x&x&1&\ldots&x\\ \vdots&\vdots&\vdots&\ddots&\vdots\\  x&x&x&\ldots&1 \end{array}\right|=0\] 
%   \end{enumerate}
